0:<Indeed, it's gread to finally take this class as a MOOC. I watched the old lectures on see.stanford.edu multiple times. Thank you for making this class. :-)>
1:<Absolutly, these courses are my bedtime TV. If I am not in bed, I am doing something else.

They work better than camomile tea,  :)  

(nothing to do with lecture quality or content, much to do with cramming last little bit of productivity into a long day)>
2:<There is a preview on google books:
http://books.google.de/books?id=1TiOka9bx3sC&printsec=frontcover&dq=convex+analysis+rockafellar+pdf&hl=de&sa=X&ei=rGTeUsCrF5Sy7AaXhYHwAw&ved=0CDMQ6AEwAA#v=onepage&q&f=false

Another preview (possibly complete?) can be found here (if illegal please delete it):
http://de.scribd.com/doc/1<phoneRedac>1/Convex-Analysis-Rockafellar-pdf

I'm not sure if there is any legal download available for the complete book.

If you're interested in convex analysis as a supplement for this course, I'd suggest:
http://www2.isye.gatech.edu/~nemirovs/OPTIII_LectureNotes.pdf
The first part of these lecture notes covers convex analysis and it is much closer to what's actually needed for this course.

If you've already learned about convex analysis and need a refresher:
http://butler.cc.tut.fi/~bossavit/BackupICM/CA.pdf>
3:<I am really new into this field .. :) and was wondering why **cant** convex optimization give us a **unique solution** if we are able to transform the problem into a convex one ?

Thanks !>
4:<thanks a lot:)>
5:<Arthur, good to see you! :-) I assume you're the same Arthur that took complex analysis on Coursera?>
6:<Thanks =) The thing I missed was that the cone given in the quiz is not $$R^2_+$$>
7:<Thanks demue, it was nice :)>
8:<I would find it more intuitive if clicking the reset would not clear all the inputs. I even fell for it twice - a quick check if one submitted a blank form would be nice. Anyway, I guess I will get used to it (hopefully :))>
9:<Video Downloads link has been created up top right. :)

The linked mp4 videos are about 400MB-700MB in size (my net speed is 256 kbps!). I am definitely going for youtube flv (much smaller). 

Thanks @cbilson.>
10:<Same here! :-)>
11:<Good lord, I am an absolute idiot. 

I did not consider $ x_1, x_2 ge 0$. So, I got a a plane to the left of $x_1 = x_2$ including the negative quadrants. So, I had a $180^o  $
cone, whose dual was the ray. 

Funny, that I got lucky and got the first option right.

Thanks for taking the time to write it in so much detail :)>
12:<I'd say remember that an affine set contains the "line" passing through any two points while convex set contains the "line segment" between any two points.
If you can differentiate between a line segment and a line, this helps you both in geometric sense and analytic sense. :)

As to why should we start the course with these definitions, I'd say probably these definitions help with formulating and solving the problems we encounter.
 
I think we had a couple good quiz questions on these. So hopefully they give a chance to apply these.>
13:<Open balls in $mathbb R^n$ for $ngeq 2$ are not open intervals. Take a look at $mathbb R^2$ and the euclidean norm. An open ball of radius $epsilon$ around the point $x_0$ will be of the form: $B_epsilon(x_0) = {x , | , | x - x_0 |_2 < epsilon }$ where $|x|_2 = sqrt{sum_{i=1}^n x_i^2}$.
  
![enter image description here][1]


  [1]: http://4.bp.blogspot.com/-yTuPwaazfK0/T9WWhfIVOEI/AAAAAAAAAEk/sriPsJcmLl0/s1600/openball.tiff

i.e. for $mathbb R^2$, we have $|x|_2 = sqrt{x_1^2+x_2^2}$

The problem is, you'll never fit such a ball into an open interval $]a, b[$. Being an open set means that for every point in the set you can find an open ball with small enough radius that is fully contained in the set. But open balls look different depending on what space you're in. An open ball in $mathbb R^2$ is different from an open ball in $mathbb R$.

So if a cone is solid, it's a relative idea. $K = mathbb R_+$ is solid in $mathbb R$ because it has non-empty interior in $mathbb R$, its interior is $mathbb R_{++}$ and open balls in $mathbb R$ are open intervals. But it's not solid in $mathbb R^2$ anymore.

You might want to take a look at metric spaces if you haven't seen it. There is a beautiful lecture series on real analysis on youtube that covers these topics http://www.youtube.com/watch?v=Ebnoxgp8mLM&list=PL0E<zipRedac>54696F<zipRedac>213<zipRedac>EC>
14:<Symbols used in "Some sets of probability distributions" were not covered in the course (unless I overlooked something). 

Could anyone point me to definitions of: 

 1. $mathbf{prob}(x=a_i)=p_i$
 2. Standard probability simplecx
 3. $mathbf{E}$ --- unless it is expected value>
15:<Not all convex functions have a unique global minimum, but the set of optimal points is always convex. Take a look at the function $f(x) = |x|$ for $|x| geq 1$ and $f(x) = 1$ for $|x| < 1$. It has multiple optimal points, but the function value for each of the optimal points is unique. 

In general you cannot simply take derivatives and set it equal to zero, because the amount of work is either too much (e.g. too many variables) or the functions are not differentiable (e.g. pointwise max of affine functions, etc). Remember also that not everything must have a closed form solution, e.g. there is no closed form solutions for the zeroes of polynomials of degree (after a certain degree, which I always forget, there is no closed form solution for $p(x) = 0$ :-)). So sometimes there is just no way around than numerical approximation by some algorithm (e.g. Newton, Gradient Descent, etc).

Quite often you're interested in $epsilon$-optimal solutions, i.e. you want a solution that is optimal up to a certain error because the error in estimating the variables is already so large, that a true optimal solution would not improve things (e.g. imagine you work in data analysis and you only know certain parameters up to +-5%)

There are generalizations to this in the case of non-differentiability called "subgradients" and "subdifferentials" (covered in Part II of this course)>
16:<I've noticed that convex and functional analysis seem to be closely related. I'm reading Nemirovski's lecture notes on convex optimization as supplementary material and the first 100 pages are a mixture of convex and functional analysis (hyperplane separation theorem as a consequence of Hahn-Banach, etc). 

I also take a course on functional analysis parallel to this one, and every second question looks as if it could have been asked in either one of the courses. 

e.g. one of the first questions asked in the functional analysis course was to prove that if a function is subadditive
$$f(x+y) leq f(x) + f(y)$$
and positively homogeneous of degree 1
$$f(tx) = tf(x) 	ext{ for } t in mathbb R_+$$ 
then the function is also convex.  

I'm wondering how deep the connection really is... I've also read that Nemirovski was originally trained in functional analysis. 

(I like it... I see the proofs in one course and the applications here. :-))>
17:<Yes, it should work (don't have the time to look at all the details, but it looks good ;)). 

When I learned about operator norms, I've noticed a common pattern in most of the proofs. To establish the lower bound one usually uses a specific vector, while for the upper bound it's more of a "reformulation" of the operator norm definition. The lower bound comes rather naturally because the operator norm itself uses a $sup$. The upperbound is usually more difficult to derive.>
18:<![sorry ;)][1]


  [1]: https://edx-west-uploads.s3.amazonaws.com/1<phoneRedac>0<phoneRedac>3.jpg>
19:<Try attempting to solve part 5 with your kidney sets. one kidney, and the other shape a convex shape that directly fits into the kidney. I did not solve this one analytically, I am not sure I can :P>
20:<Yes, you're right. Sylvester's criterion is both sufficient and necessary. That's why I said the question is rather weird since it doesn't want to have the minimum criterion (all leading principle minors) as an answer. Most of us are used to interpret question that way. 

I tried to formulate it in a way that does not spoil the solution (immediately). That's why I said "what does Sylvester tell you if you apply it to a diagonal matrix", etc. Because after all it's our homework. ;)>
21:<Dear all,

if you have read the page 22 of textbook, 
it says an affine set C can be expressed as the summation of a subspace and a point x0 in C

C = V + x0

here it requires that x0 has to be in C

but later the book gives an example C={x|Ax=b} and states that subspace for this C is null space {x|Ax=0}

Does that mean C = V + b? but b is definitely not always in C! Ab = b ?!

Could anybody explain this? Thank you so much in advance. :)>
22:<I think it should work.

$tr(A^TX)$ corresponds to taking the sum over the diagonal elements of $A^TX$, but the diagonal elements are given by the inner product between the $i_{th}$ column of A (= $i_{th}$ row of $A^T$) and the $i_{th}$ column of $X$.

The function $vec$ (if defined as $A(:)$ in matlab) takes the columns of a matrix and creates a long vector out of them. If you then take the inner product between both, it'll be the same as $tr(A^TX)$.

[I just randomly checked it with a couple matrices in matlab, it works.]>
23:<Thanks a million!  :)>
24:<Well, maybe we can forget the last remark. I'm not sure and way too tired. Anyone care to prove it? :D>
25:<maze4.net description makes a lot of sense. Moreover, it clarifies the motivation.

Thanks very much :).>
26:<I don't think it's ambiguous. From $geq$ does not always follow $>$. But in my opinion it still would be better to use "necessary" and "sufficient". [But it still caught me on the first try.]

Edit: I had to edit my answer, was too tired when answering. :-)>
27:<Yes, it would make it positive definite. I was too tired! Of course from $>$ follows $geq$ and not vice versa! :-)>
28:<Yes, it's technically unambiguous. $geq$ does not imply $>$. I had to edit my original answer. Sometimes one does silly mistakes. :-)>
29:<I did this problem with Excel SOLVER =) 

The question asks for *optimal values*. So  each answer should be a single real number.>
30:<tl;dr: +1, interpreting risk as $sqrt{x^TSigma x}$ produces the correct result.

Non-economist ramble: 

In a way, it makes sense that the "risk" should be the standard deviation. It is perhaps intuitive if one considers the investment as a one-time deal. Then the "risk" is the size of a likely ($1sigma$~30%) fluctuation. But we should be careful and say that $ar p^Tx$ is the average return *per deal*. Similarly, the variance $x^TSigma x$ is the expected square difference from $ar p$ *per deal*. This has consequences if we consider many successive such deals (which I guess is not too uncommon).

Let's call $mathcal D = x^TSigma x$ the "diffusion constant" (it has units $$^2$/deal). After trying the investment plan $N$ times, that is making $N$ such deals, the mean return is $Nar p^T x$. But the expected square deviation from $Nar p^T x$ scales like $mathcal D N$, and not $mathcal DN^2$. One could perhaps expect that the displacement after many deals should scale as $sqrt{x^TSigma x}N=sqrt{mathcal D}N$, so that the the square displacement should scale as $mathcal D N^2$). But this is not the case, simply because sometimes you win, and sometimes you lose. 

With that background, $mathcal D$ is the more relevant parameter. Of course it doesn't matter, as long as one knows how to interpret the numbers. Well, if you do vector optimization with some sneaky scalarization it will affect your result..

At any rate, I am not an economist, so it would be nice if the problem formulations included explicit definitions for such specific concepts, however trivial in their respective field.>
31:<Thanks! The assignment is not misleading -- it is wrong! :-) With two attempts, you just can't afford to waste one due to erroneous instructions!>
32:<I see. The point is treat epi(f) as a vector (x,y).
It's very clear explanation! Many thanks for your help! :D>
33:<Use rand('state',5) to reset the generator for rand and then use randn('state',5) to reset for the S matrix. And use standard deviations instead of variances as others have pointed out :)>
34:<Nice example, I got it! Thank you :)>
35:<=) My old job was asset allocation at an SWF (Sovereign Wealth Fund), so SD is the habitual measure. You're absolutely right that it's a units thing. People are a lot more comfortable talking about risk in the same units as returns (%) than in an odd unit like $%^2%. Scalarizing with risk measured in SDs means that $$/lambda$$ is unit-less.

Jonas - your argument on square-root scaling requires independence of the bets/events. Returns to perfectly correlated bets would scale with N (which violates many finance assumptions as such a market would be perfectly predictable. )

[As an aside - it looks like Markdown hates me]>
36:<Jonathan: you're completely right, thanks for the comment! The real thing is likely in-between completely noisy and completely predictable, which would correspond to a stochastic process with finite correlation time. In statistical physics we know how to do some perturbation theory for that. Also, the returns distribution is likely skewed ("non-gaussian"), which also would take some more calculation to incorporate.. (it so happens, that turbulence statistics are also skewed, and have finite correlation time..).

A second critique to my argument is that one would likely change $x$ between "deals", so that would also have to be considered, but surely more well-paid people than me are already considering these things in painful detail :)

Cheers>
37:<Thanks guys, I just needed to take the sqrt of my answers like you said... Was a bummer to see all wrong on 1st try :)>
38:<Thanks. I got it :)>
39:<Remember that the question states we are looking for minimum portfolios with the *same expected return as the uniform portfolio* :)>
40:<Come join us over [here][1]. :)


  [1]: https://class.stanford.edu/courses/Engineering/CVX1<zipRedac>1/Winter2<zipRedac>14/discussion/forum/i4x-Engineering-CVX1<zipRedac>1-hw3/threads/52f<zipRedac><zipRedac>733c91dff<zipRedac><phoneRedac>78>
41:<Yes, thanks indeed...

The sqrt requirement is a bit misleading (this is an overstatement :)) when the problem statement *explicitly* says '**with risk measured by portfolio return variance**'>
42:<I'm a little confused about the third and the forth example in Example 3.14. The third one says that h(z) is a concave function. But as I know, the form of h(z) is exactly the lp norm and every norm is a convex function...Is this a contradiction? How to prove the h(z) in the third example is a concave function and h(z) in the forth example is a convex one? :)>
43:<[Edit: didn't see your edit, sorry... here's my answer anyway.]

First, check out [this thread][1]. You should be entering the risk as standard deviation, not variance (yes, the question doesn't mention this, you should somehow just know :)

As for the change to an inequality not affecting the outcome, that is just as it should be, since minimizing risk naturally uses up all your leeway in return.

  [1]: https://class.stanford.edu/courses/Engineering/CVX1<zipRedac>1/Winter2<zipRedac>14/discussion/forum/i4x-Engineering-CVX1<zipRedac>1-hw3/threads/52f<zipRedac><zipRedac>733c91dff<zipRedac><phoneRedac>78>
44:<Sorry for the re-posting. I didn't check the previous posts carefully. Clear explanation. I began to realize this would not be an easy course now:) Thanks.>
45:<You can create the plots by using wolframalpha (or if you have it, you can also use Mathematica).

http://www.wolframalpha.com/input/?i=plot+xy

I used the function from the homework. $f(x,y) = xy$>
46:<it is not hard, it is high school level. only basic things :) the worse is that it is both true and false statement :)>
47:<Thank you  :)>
48:<It seems that the answer for this quiz is wrong because I submitted exactly the right answer, but it was marked as wrong ;)>
49:<Hi all,

I just went through the homework assignment on portfolio optimization, and I was wondering if anyone could provide some intuition behind the data that was provided for the problem:

n=20;
rng(5,'v5uniform');
pbar = ones(n,1)*.03+[rand(n-1,1); 0]*.12;
rng(5,'v5normal');
S = randn(n,n);
S = S'*S;
S = S/max(abs(diag(S)))*.2;
S(:,n) = zeros(n,1);
S(n,:) = zeros(n,1)';
x_unif = ones(n,1)/n;

In particular, I'm not sure why the definition for pbar had the scaling .03 and .12 and why we divided the matrix S'*S by max(abs(diag(S)))*.2. 

Thanks in advance!>
50:<I believe you just gave up (at least part of) the answer :)>
51:<Hi =)

I'd be thankful if you could explain how the primal problem in slide 5-14 got its dual problem .. I had a look at SDP but could not get it how it is being formulated 

Thank you !>
52:<Here some intuition...

$p = 	ext{ drift } + 	ext { random stuff }$ 

You have a drift parameter, in this case $0.03$. The market itself tends to have some drift, i.e. the market portfolio doesn't have expected return 0. 

The "random stuff" is the idea that each asset has its own behavior, e.g. asset $i$ can go up, while asset $j$ can go down. 

ones(n,1)*.03 is your drift

[rand(n-1), 1); 0]*.12 is the random behavior of your assets, note that the last asset does not have any randomness in it (it's risk free, e.g. some long-term bond that guarantess 3% return).

S = randn(n,n);
S = S'*S;
S = S/max(abs(diag(S)))*.2;
S(:,n) = zeros(n,1);
S(n,:) = zeros(n,1)';

Creates a random covariance matrix. 

It's a simplified model for "educational purposes." If you're interested in the topic, check out UChicago's Asset Pricing course on Coursera.>
53:<Actually, by showing above the Matlab output, you give up the answer to the second question :)

You're right about the objective function: I believe that is the key in solving this problem. Once you factor correctly the quadratic function to be minimized (so it can be used by CVX), the rest seems to be just work for the computer...

BTW: I got the same result for the dual variables (and therefore for the primal ones)>
54:<Ah of course! Fixed :)>
55:<That is a fairly good indication of an error :)>
56:<Thanks demue, 

That clarifies it somewhat, so is it just a terminological mashup? Like, why not just say "Linear Function" instead of "Affine Function"? Do they really mean the exact same thing?

Im not asking for the sake of being pedantic, I just dont want to be caught off guard one day and say "linear function" when the correct way would be to say "affine function", etc. 

If they are truly the same, I'd be ok with that! I just want to make sure... :-)

Thanks.>
57:<Dear administrators,

 Can future problem sets PLEASE specify the accuracy requirement?

 I'm considering asking for my money back ;)>
58:<@demue thanks for your link and help! I think it is much clearer now. :-)>
59:<I have the same problem here.

I've already used my 2 submission. In both times, my answers were graded wrong. I didn't know why until I clicked the "Show answers" button. The problem here is the grading system using a precision of two digits. Poor me :)

It's not fair :).

I hope the admin help us fix this "small" problem.

Thank you>
60:<@demue, Thanks - I got it - this was actually an easy problem... :-)

One detail: Are we writing this as $p^T f(a)$ or as $f(a)^T p$? I know it doesnt matter mathematically, but it helps me think about it better. 

So is the set we are 'solving' for here $p$ or $f(a)$? 

Thanks!>
61:<Just blowing off steam...

One reason I took this course was to understand the KKT conditions, which seemed totally mysterious to me. The good news is that they now appear absolutely trivial :) So I was feeling really, really happy.

**Then**, Prof. Boyd casually mentions that the conjugate of a norm is the indicator function of the dual norm ball. It then took me over an hour to figure out what the #*! that sentence means since I had never heard of an indicator function, a dual norm or a dual norm ball. Sigh...>
62:<I like the class a lot ... in the sense that it has a lot of potential, etc. 

I think that some thing can be made much more clearer by throwing a couple examples in the lecture. It wont cost much but take a student very far... I think he is a great teacher, but there are some things that he might omit that would be very helpful to us peons. 

Right now I am averaging **16 hours** for understanding **1 week's worth of lecture.** This is because I need to de-compress what he says with some examples to internalize it. I think this process can be made more efficient IMHO. 

The forums are very very helpful - esp @demue - I think without him I would not be where I am today. :-)

Hopefully all the beginning material is 'cough medicine' that we learn very well once, and then apply it. I hope that my average hours spent goes down as the class proceeds.>
63:<It's always could to explore an open question by yourself. You learn much more if you find the solution on your own.

We all like this class... I spend way too much time on the forum. I still haven't done most of the homework for duality and I still have to do one question from the previous week. :)>
64:<You're welcome. :)>
65:<i too love this although i have few doubts! if i got any doubt, it should actually be my fault :-D i love this truly :-)>
66:<I'm wondering the same thing :)  I'm assuming the staff haven't seen the thread yet.

There were issues with HW4 P1, that they fixed https://class.stanford.edu/courses/Engineering/CVX1<zipRedac>1/Winter2<zipRedac>14/discussion/forum/i4x-Engineering-CVX1<zipRedac>1-cvx/threads/52f915a1ec<zipRedac>f93c12e<zipRedac><zipRedac><zipRedac><zipRedac>36 (though  looking at the thread now there may be more)>
67:<Indeed, probably my explanation got a little too technical. :)>
68:<@demue, 

Yes very true. Even for me, my field is engineering so already very 'mathy', but a lot of this stuff here is my first _ever_ exposure to it. (Sets, halfspaces, etc), so there is a very large (concave :-) ) learning curve associated with it.

The good this is that (myself included), once we understand - like really understand - this material, it becomes automatic and instinctive. Thats important. 

Just as how when you learn a new language in the beginning you parse letters to make a word, then next word, etc etc, reading can take forever. But after a while you just 'see' a word. 

The thing about math I have found though, it that by far, examples can go a very very long way. A couple examples for each 'statement' even if they seem obvious to the teacher I think will take care of 80% of ambiguities found by a student. 

Again youve been a great help! What is your background? Are you a TA for this class?>
69:<Hey, I was having the same problem, so I bit the bullet and installed MATLAB. [Here is the link to the data.][1]

The data are in two separate .mat files. (heuristic_suboptimal_solution, simple_portolio_data). Don't worry there are no answers =).

If you have scipy installed you can load them with:

    scipy.io.loadmat(filename)

It will return a dictionary with the all the values. For full documentation you can refer to this [link to the docs.][2]

Hope this isn't too late.

Chris


  [1]: https://www.dropbox.com/s/qxn6d8owg1oxtgw/data.zip
  [2]: http://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html>
70:<Thanks.  I made a table of lambda3 for the different precisions as you suggested, and it varies considerably.
I also factored the objective, (1) leaving the linear term outside quad_form, and (2) bringing it inside via quad_form(x+u,P) - constant.
Both give the same opt_val, x1,x2 and KKT conditions are satisfied, but even more variation in lambda3.

So, are people just not answering this question now? Getting it wrong? 
Or right by pure luck--or by having previewed the 'right' answer before the reset :)  Makes me wish I had made two mistakes sooner.

Done with course version of Matlab, free solvers, on Windows Vista.>
71:<:-) ahh, thanks, didn't thought of looking there.>
72:<I appreciate your active participation on discussion forum. :)>
73:<@TCubed: I'm 22. Yes, the MOOCs are very good and make me very happy. :-) But we don't have enough pure math MOOCs yet. It's still in no comparison to what you could study at a good university. 

@Sarah: I know. It is possible but you need 3 years of work experience. I couldn't get this work experience yet [for the same reason I could not finish my a-levels via distance learning]. 

Yeah, I've read about Bologna a lot. Back when I was an auditing student in Bonn (~2007+) it was still much more relaxed. But it might also have been because I only attended the lectures and didn't have to completely fit into the system. 

I don't have any opinion about it until I have experienced it, and I suspect that it's different from university to university. If you take a look at Bonn and its math curriculum, you can see that you basically have a lot of choices relative early in your studies. You have to take Analysis 1+2, Linear Algebra 1+2, Algorithmic Mathematics 1+2 but then beginning with the 3rd semester you only have to satisfy some breadth requirements and are free to choose whatever you want subject to this constraint. 

Though, I know some science students at other universities and they don't have a choice before their 4th or 5th semester. They complain much more.>
74:<@demue dann bist Du also aus Bonn? :-) I'm, as you might have guessed, from munich. 
I know about this three year barrier and they are bureaucratic and everything ( german speciality ;-) …) but there must be an other way. I also have a very unusual cv - well, the best thing you can say about it, is that it's not boring, but that's all - so, if i can help you, let me know. (i know some students from the asta, they might know a way to bypass this stupid bureaucratic barriers. I mean it's ridiculous, 90% of our lectures are much easier and much slower than this one, if you can do this kind of MOOCs why the ### shouldn't you be able to study at an university)

…and Bologna, grrrr, we haven't got any real choices until the 4th semester ( i'm sec year undergrad), that's the reason why i'm doing MOOCs :-)>
75:<Heyyy, where are these assignments??? I am starving !!  :))>
76:<Yes, I actually started to think about coming to the US. 

Indeed, it's slightly ironic that Sebastian Thrun is German. I took the first iteration of his AI class :-)>
77:<@Dennis, well i wouldn't call it 'relaxation' - some of this MOOCs gave me more than one sleepless night- but definitely fun :-)
I think the german hostility towards MOOCs has several reasons. Mostly insecurity. With an online course education suddenly becomes comparable.And in the last few years (in germany) it had been mostly a political decision which university becomes 'elite universität'( which manly means more money), they tried to copy the 'american system' forgetting completely that one of the main strengths in the german education system is the brought non-professorial-teaching staff. And with comparable education they suddenly realize that this silly status of an 'elite university' is on very very shaky grounds. 
I think in the course of time this MOOCs will have the same impact on education as recording technic on music. I'm a professional musician too, played some time in an opera orchestra in Berlin, so I had experienced this progress from 'the other side'. It is definitely very stressful to have an audience which knows at least two or more wonderful famous recordings of the very same piece and is consciously or unconsciously comparing your performance with them. But the bright side is that the brought technical level has improved rapidly, today even small orchestras are expected to be able to play pieces like Le sacre du printemps, a piece that about 90 years ago was considered to be nearly unplayable. So, yes i can understand them a very very little bit. It certainly isn't easy as a professor to have students in front of you who continuously comparing your performance with the online version.
But with MOOCs, we are in 'the audience', we are those who benefit from this process :-) Give it a few more years and i'm sure -even in germany (ok, at least 40 years)- they'll change sth., this progress can't be stopped any more.>
78:<@SarachC_Sachs Yes exactly, professors who are confident about themselves need not fear MOOCs, instead, they would probably embrace them. 

BTW you and @demue since I assume you are both German, probably have heard of "iversity"? I believe it was founded by a German entrepreneur. 

@demue One thing about all the skepticism and all the old fashioned teaching, is that they try to do too many things at the same time, and spread out thin. For example in old-education they try to teach and give hw and grade it and test you and tutor you. and and and. :-) It is too much, this is one of the most salient reasons they fail, to say nothing of the fact that when prices are so expensive, it becomes about 'passing' and not 'learning'. To be honest, MOOCs are actually ALSO failing in some regard because they have tried to just copy/paste this paradigm, which does not work. Sebastian Thrum also said that his completion rates are abysmal, and did not know why. 

I am actually in the process of making some MOOCish videos as well, but I have a completely different model: Complete factorization of the and.and.and we see in current education. 

Shoot me your emails if you guys are interested: leanlearninglabs@gmail.com and just let me know (briefly) what you guys are interested in. :-)>
79:<@spatry I agree that it's tempting to see $y$ in $V^Ty=p$ as a probability but it doesn't really work. First, $mathbf{1}^Ty
eq1$ (although it's kind of close) and you can't add that as a constraint and get reasonable answers.

I've worked this problem out and gotten "correct" answers but I have no feel for what's really happening.>
80:<@Sarah, ich will das System gar nicht zerpflücken. (ich mag wirklich vieles an unsere System)

I've never said everything is bad. I think a lot of things are really good. It's free, good quality (with some really, really good universities and faculties), and we specialize early (because we meet the "general education requirements" in our a-levels). I like this system a lot, I just dislike the fact that it's very bureaucratic at times. :)

I don't dislike the fact that the exams are tough. We start from 0 in every subject, i.e. even if you don't have the best background in the subject, it's possible to do it. I don't think it's too difficult. I think the problem is somewhere else. I think the quality of our a-levels (abitur) has gone down. e.g. we don't cover proofs in our advanced math curriculum (leistungskurs) anymore. Having one year less is a joke. I regularly have to tutor first year students in engineering and math... Quite often they are literally 'shocked' about the difference between school and university.

We tried to minimize the time, cost, etc but forgot one thing. We had a totally different system than other countries. We specialize early and this required to have a good basis (complex, difficult a-levels and enough time to prepare.)
I remember reading (probably in Spiegel Online?) that some universities wouldn't mind to extend the bachelor from 3 to 4 years because students don't have the necessary background anymore (i.e. have a calculus sequence similar to the US system during the first year). 

Take a look at the STEP exams required for Cambridge. I highly doubt that you can do STEP 2/3 with our curriculum. If you put all math majors into Harvards math55 and tell them "You're out if you fail.", You'd have similar drop out rates. I just don't think you can optimize both school and university for time, cost, etc without changing the system or losing quality.>
81:<@Dennis, :-) I think we have a perfect example what you definitely shouldn't do with optimization.
 ….and you gave me a very critical keyword, exams….we have all our exams in February, ähhh now…. and this course becomes dangerously time consuming ;-)

Wenn Du möchtest kann ich aber gerne mal bei der Asta nachfragen, ganz vorsichtig und unverbindlich. Ich kenne da ein paar Leute und die kennen sich mit den bürokratischen Abgründen -glaube ich- ganz gut aus. Manchmal findet sich dann doch ein ungewöhnlicher Weg und das würde ich Dir doch sehr wünschen!>
82:<I have a quick question about the second problem in HW6. How good does our solution approximate the true continuous distribution considering that in reality $P(R_1-R_2=0)=0$? I would naturaly accept the continuous one to be just some smooth approximation of the discrete one but given the conditions and the entire problem setting, I am not completely certain about it... :) Cheers!>
83:<I started with the functional analysis course at coursera but couldnt find time to continue. I guess I will just watch the videos. :D>
84:<Oh and btw, I got the correct answer :)>
85:<Hi~I have one small idea after learning the "least-norm problems":

minimize    norm(x);  
s.t.  Ax == b


I want a sparse solution x*.  
I think the most appealing representation should be to minimize norm(x, 0)(i.e., find the solution with the fewest number of nonzero coefficients of x). But unfortunately, it's a combinatorial optimization problem and very hard to solve.

If I approximate this problem with a convex one, the best choice of the objective function should be to minimize norm(x, 1)(because for norm(x, p) & p < 1, the norm is not a convex functon).

I want to do better. What about choosing the objective function as sqrt(abs(x1))+...+sqrt(abs(xn))(or just norm(x, 1/2))? The objective function is not a convex one, but if we optimize this objective function, we can get a sparser solution x*. Another thing is that the objective function is a quasiconvex function, and we can solve it.

My question is: Does it worth it if I get a sparser solution in exchange of more computation(a quasiconvex problem)? I want sqrt(abs(x1))+...+sqrt(abs(xn)) as my objective function, are there better expresion of my objective function or are there some more efficient algorithms except for solving a quasiconvex problem?

2)Another question: as for the scalarized problem norm(Ax+b)+belta*norm(x), how do I stuff it in my real work? I have difficulty with choosing the best value of belta. another question is if I want to optimize multiple obectives, the only way is to convert my problem to a one-objective problem (just like the scalarized problem, weighted sum my obJectives)?
Of course I know we can covert some objectives as the constraints of my problem(i.e., the area of my designed circuit shouldn't be greater than blablabla..:-))

Thank you so much!:)>
86:<Yes, I got the correct answers too. It was a grader problem :-)>
87:<Oh, wait, you are right, THEY are confusing p* and x*. :-)>
88:<You have an unperturbed problem which gives a specific result…call it $p^*(0,0)=p^*(u,v)vert_{u=0,v=0}$. If you want to know something about what happens at non-zero values of $u,v$ without rerunning the optimization to find the exact answer you can use

$p^*(u,v)geq p(0,0)-u^Tlambda^*-v^T
u^*$

to find a lower bound. Hope this helps.>
89:<Sweet. You used a much simpler way. :-)>
90:<@jgreenb2 This is very good question :).
I guess it is a problem statement which puzzles you.
Actually, an implicit constraint in the statement is that you have to invest all the money in some set of assets. And if there is no risk-free one (cash, basically), then your portfolio consists of risky assets only and thus bounds go wild.
E.g. if you've sold a collar, then you should spent all the money buying calls, puts and stocks. And you cannot just buy a collar, since you have to finance the purchase by selling some calls/puts. That's assuming there is no risk-free asset.
It's not realistic, of course, and limits hedging opportunities.>
91:<Duality was the answer to my questions :)>
92:<I am trying to use CVX to solve my own problems and have found a strange effect. 
The problem is to minimize the maximum element amplitude of $Aw$ while the inner product with another vector is 1, $c^Tw=1$. $A$, $w$ and $c$ have complex values.
My code for this problem is the following:

    cvx_begin
      variable w(128) complex
      minimize(norm((A*w),Inf))
      subject to
        c*w==1;
    cvx_end

$A$ is a $235	imes128$ matrix, $c$ and $w$ is $128$ element vectors. This version runs nicely and returns solved.

Now I wanted to do a minor transformation, I add a normalization to $c$ before the optimization in this way:

    c=c/norm(c);
    cvx_begin 
      ...

Now, the solver returns "Infeasible", even though scaling the previous solution by $|c|$ should give a solution to this problem. The size of $|c|$ is approximately $5cdot 10^8$.

Is there anyone that can enlighten me to why this happen? Is my understanding of the problem wrong, do i destroy some numerical property when I scale $c$ or something else?

PS: If I also scale the matrix $A$ I get a different(not only rescaled) optimal $w$, but it is equally good with regards to the cost function.

Edit: 24.02.14 - Addition of example data

The example provided in the following code has similar behavior as my original problem:

    M=243; N=128; n=1:N; 
    sinAng=linspace(0,1,M);
    rng(5,'v5normal');
    B=exp(1j*pi*(sinAng'*n))+complex(randn(M,N),randn(M,N))*0.1;
    B=bsxfun(@times,B,cos(asin(sinAng))');
    A=B(19:end,:);
    c=B(1,:);
    % Scaling data
    kc=1; % Scaling factor for c
    kA=1;     % Scaling factor for A
    A=kA*A;
    c=kc*c;
    % Optimizing
    cvx_begin
      variable w(N)
      minimize(norm(A*w,Inf))
      subject to
        c*w==1;
    cvx_end

cvx_status for different scaling constants $k_A$ and $k_c$:

 - $k_A$=1e-8, $k_c$=1e-8: Solved
 - $k_A$=  1, $k_c$=1e-8: Solved
 - $k_A$=1e8, $k_c$=1e-8: Infeasible
 - $k_A$=1e-8, $k_c$=  1: Solved
 - $k_A$=  1, $k_c$=  1: Solved
 - $k_A$=1e8, $k_c$=  1: Failed
 - $k_A$=1e-8, $k_c$=1e8: Solved
 - $k_A$=  1, $k_c$=1e8: Inaccurate/Solved
 - $k_A$=1e8, $k_c$=1e8: Failed

Theese scalings should only lead to equivalent problems, so all the results should be equal.>
93:<It's also interesting to look from a linear regression point of view :). So, you are trying to fit a linear model which predicts discounted expected outcomes (in different states of the world) based on the observed prices.
So, if there are many states of the world and too few regressors (asset prices) then you are likely to under-fit. And the risk-free asset is an intercept term :).>
94:<Sorry, my last comment was wrong, I've got entangled.
One tries to predicts prices based on expected future payoffs, of course, and fit the model based on observed prices of traded assets.
So, the amount of regressors equals #(state of the worlds) actually. And, since the risk free asset has the constant price in future, it corresponds to an intercept term.
And there is a constaint: the weights (risk-neutral measure coefficients) should be non-negative.
So, if there are too many states of the world/too many regressors, it's easy to over-fit. But it's unlikely to generalize well, since there could be many weight assignments that fit well, and they give different predictions.
I'me not an expert in linear models, but there should be clearly a nice bayesian interpretations, stating that the less assets you have the more variance in predictions you get :).>
95:<Okay, thanks for clarifying that. I didn't realize this when I posted, but there is an analogy to scalar-valued functions: A scalar-valued function is convex if and only if its epigraph is convex. And if a vector-valued function is convex, then the epigraph form of its image $mathcal G$ is convex. This brings up a couple of questions:

a) Can we prove this?

b) Does the converse hold? Ie. if the epigraph form of a vector-valued function's image is convex, does that imply that the function is convex?

(I know I'm going off on a bit of a tangent here :)>
96:<Don't know really... may be they proofread a new version of the book?;)
 Any ideas on how could one alert the staff about this small problem? thanks!>
97:<There is an issue with this problem. The values for lambda in this problem are not uniquely determined. (So neither are the p_pred values) It is a good exercise to work out all the possible valid lambda. 

See https://class.stanford.edu/courses/Engineering/CVX1<zipRedac>1/Winter2<zipRedac>14/discussion/forum/i4x-Engineering-CVX1<zipRedac>1-cvx/threads/52f915a1ec<zipRedac>f93c12e<zipRedac><zipRedac><zipRedac><zipRedac>36 for more info.

To staff: If you disagree I'm happy to send my explanation of why I believe this is the case if you give an address to email. :)>
98:<The function is neither convex nor concave in $mathbb{R}^2_{++}$. Take the points 

$x_1 = (1, 2) \ x_2 = (2, 1) \ x_3 = (1, 1) \ x_4 = (3, 5)$

Then

$0 = h(x_1/2 + x_2/2) < h(x_1)/2 + h(x_2)/2 approx 0.6 \
0.020 approx h(x_3/2 + x_4/2) > h(x_3)/2 + h(x_4)/2 approx 0.016.$

How I did it: I plotted the function on $mathbb{R}^2_{++}$, it looks convex-ish, but from a certain angle you can see that the cross-section curves down very slightly. Then to actually prove that it's not convex or concave, I calculated a few points. :)>
99:<Thanks, hopefully between that and the textbook, I can grok this :)>
100:<Same here.

I believe Q1 in Duality HW is still not well posed.
Depending on the machine precision, the default CVX does pick only one answer out of 4 shown as "correct" on CVX site for Question 1 part (c).

Here is a simple MATLAB script to demonstrate this:

% Duality---------------------------------------
clear all
n = 2;
u1 = -2;
u2 = -3;
S  = [1 -1/2;-1/2 2];
A = [1 2;1 -4; -1 -1];
RHS = [u1;u2;5];
cvx_begin
    variable x(n);
    dual variable y;
    minimize (x'*S*x-x(1));
    subject to
        y: A*x <= RHS;
cvx_end
p_pred=ones(9,1)*cvx_optval;

Du = [<zipRedac> <zipRedac>;<zipRedac> -.1;<zipRedac> .1;-.1 <zipRedac>;-.1 -.1; -.1 .1; .1 <zipRedac>;.1 -.1;.1 .1]
for i=1:9
    u1 = -2+Du(i,1);
    u2 = -3+Du(i,2);
    S  = [1 -1/2;-1/2 2];
    A = [1 2;1 -4; -1 -1];
    RHS = [u1;u2;5];
    cvx_begin
        variable x(n);
        minimize (x'*S*x-x(1));
        subject to
            A*x <= RHS;
    cvx_end
    p_pred(i) = p_pred(i)-Du(i,:)*y(1:2);
    p_exac(i) = cvx_optval;
end

dp = min(p_exac(2:9)'-p_pred(2:9))
([p_exac(2:9)'-p_pred(2:9)]<=dp)
% here one can see that the corresponding scenario is #6
% note that if we purturb dp slightly, say by .<zipRedac><zipRedac><zipRedac><zipRedac>1
% then the other "correct answers" start to show up as well
([p_exac(2:9)'-p_pred(2:9)]<=dp+.<zipRedac><zipRedac><zipRedac><zipRedac>1)>
101:<Thanks, actually I've found an explanation to this problem. The key is the meaning of "unbounded". What we consider the unbounded from above, but I guess the solution to this problem is to think unbounded from below, i.e., the optimal solution of the primal problem is negative infinity. In this case, since the optimal solution of the primal problem is always an upper bound of the dual problem, then the optimal solution to the dual problem should also be negative infinity, which is also unbounded from below. 

Hope this explanation helps :)>
102:<I find this helpful and wanted to share this if anyone else finds this helpful. :)
http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3274/pdf/imm3274.pdf>
103:<@mrothe: So I should use a piece-wise function for the collar as well? I tried here but I keep getting the problem unfeasible, with infinity for the optimal value. The payoffs are the v_i's right? I hope I am not breaking any honor code with this, but these are my prices:

p_known = [1; 1; 0.06; 0.03; 0.02;0.01;];

I really don't have a clue where is the error.>
104:<It seems that I'm not the only one :)>
105:<Hmm, I think the reason is that convolution only works when two variables are independent:)>
106:<Hi all,

I have been struggling with prob4 for a while. I established V matrix as a 200*7 matrix while y is 200*1 vector and p is 7*1 vector with [p_known; p_collar]. However, when I used CVX solving minimize p_collar under these two constraints:
  (-1)*V'*y + [p_known;p_collar] == 0;
   y>=0
It gave me the following warning:
*Trivial infeasibilities detected; solution determined analytically.
Status: Infeasible
Optimal value (cvx_optval): +Inf*

Does anyone have ideas about what's wrong with it? 

P.S. I am also confused about whether the K of put or call option is (Strike*Price)in the table. And whether the p of the put or call option is simply "Price" in the table.

Thanks!>
107:<I get the same thing when I have the constraints
         y >= 0;

        -V'*y + [px;pcollar] == 0;
I tried to split the constraint into two (fixed prices and the collar) this came back as solved provided that y (200x1) is initialized to some >0.
The values returned for the collar varied on how y is initialized>
108:<All are nice.. :) BTW I like factorization methods. block forms are super easy to remember and implement for factorization methods.>
109:<Sure, I don't claim prizes for well-commented code, but here's a script that gave points. (EDIT: sorry, copied wrong assignment code ;)

    clear all
    clc
    
    m = 200; %outcomes
    n = 4; % existing options
    r = 1.05; % return on safe option
    F=0.9; % floor F and ceiling C on collar
    C=1.15;
    
    % prices for safe, underlying and then  existing options
    p = [1, 1, 0.06, 0.03, .02, .01]'; 
    
    K = [1.1, 1.2, .8, .7]; % existing strike prices
    
    S = linspace(1/2, 2, m); %possible outcomes
    
    V = zeros(m, n+2+1);
    for k=1:m
       V(k, 1) = r; % safe option
       V(k, 2) = S(k); % underlying asset
       for l=1:n % existing options
           if K(l)>1 % call
                V(k, 2+l) = max([0, S(k)-K(l)]);
           else %put
               V(k, 2+l) = max([0, K(l)-S(k)]);
           end
           
       end
       V(k, 2+n+1) = min([max([S(k), F]), C])-1; % collar
    end
    
    Vt = V';
    Vt1=Vt(1:(end-1),:); % split V into known part and collar part
    size(Vt1)
    Vtlast=Vt(end,:);
    size(Vtlast)
    cvx_begin 
        variable collarP
        variable y(m)
        minimize collarP
        subject to
            Vt1 * y == p
            Vtlast*y == collarP
            y >= 0
    cvx_end
    minprice = cvx_optval
    
    cvx_begin quiet
        variable collarP
        variable y(m)
        maximize collarP
        subject to
            Vt1 * y == p
            Vtlast*y == collarP
            y >= 0
    cvx_end
    maxprice = cvx_optval
    
    range = [minprice, maxprice]>
110:<Ok, here's mine.

    F = 0.9; C = 1.15;
    m = 200; n = 7;
    S = linspace(0.5,2,m);
    S0 = 1;
    pinit = [1 1 0.06 0.03 0.02 0.01]'; % Initial 6 known assets price 
    
    % Setup final value of assets, V
    % 200 scenarios, with 7 assets: (risk_free, stock, opt1:opt4, collar)
    V = zeros(m,n);
    V(:,1) = 1.05; % r
    V(:,2) = S';  % underlying stock price
    V(:,3) = max(0,S'-1.1); % Call option1: Strike price = 1.1
    V(:,4) = max(0,S'-1.2); % Call option2: Strike price = 1.2
    V(:,5) = max(0,0.8 - S'); % Put option3: Strike price = 0.8
    V(:,6) = max(0,0.7 - S'); % Put option4: Strike price = 0.7
    % Collar option:
    V(S > C,7) = C - S0; 
    indices = find((S >= F) & (S <= C));
    V(indices,7) = S(indices).' - S0;
    V(S <= F,7) = F - S0;
    
    % Find lower bound of collar price pn
    fprintf(1,'Computing the lower bound of option price (collar): 
');
    fprintf(1,'# Using the dual formulation of option pricing...');
    cvx_begin
        variables pn y(m)
        minimize( pn )
        subject to
            V'*y == [pinit;pn]
            y >= 0
    cvx_end
    fprintf(1,'Done! 
');
    lb = pn;
    
    
    % Find upper bound of collar price pn
    fprintf(1,'Computing the upper bound of option price (collar): 
');
    fprintf(1,'# Using the dual formulation of option pricing...');
    
    cvx_begin
        variables pn y(m)
        maximize( pn )
        subject to
            V'*y == [pinit;pn]
            y >= 0
    cvx_end
    ub = pn;
    fprintf(1,'Done! 
');
    disp(sprintf('[lower,upper] = [%f,%f]',lb,ub));>
111:<I think it comes naturally with the modelling section of the course that you encounter real world applications unknown to you. 

But I agree that it is unfortunate to spend 2-3 hours on understanding the words of a problem. I don't think we get a better feeling for how convex optimization problems look or how to model them, just because the wording of the question is difficult. 

I think the main idea of the problem was to emphasize the use of Farkas' lemma. Sadly, it did not really put the focus on it. If you understood the finance behind the problem, all the code was given in the book. You didn't have to understand much for it. I'd have been happier if the problem itself wasn't about stocks. Change stocks to something else and let us think about how to solve it on our own (i.e. don't spoil the connection between the problem and Farkas' lemma). 

Having said that, I really enjoy this class! The lectures are fun to watch (I like his humour). Boyd's teaching style is very intuitive. The content is interesting and the details are often quite challenging. A lot of the connections to other fields became much clearer after working through the material.

I hope we'll see EE364B as a MOOC next year. I know the material is online and that we can work through it on our own but it's much more fun to do it in a MOOC setting. I really enjoyed the discussion forum.

I'd also love to see EE464 as a MOOC. :-) The content looks awesome: http://lall.stanford.edu/ee464/ Sadly I haven't found the time to work through it yet.>
112:<Hi everyone,

do you have some hints on how to solve this problem? I can't make it either convex or quasiconvex and I am out of ideas... I tried computing gradient and setting it equal to zero and a bunch of incoherent experiments that lead to my minimum being about 2.5...

Thanks :)>
113:<Is there any way to get an intuitive feel for if a problem may be formulated as a convex problem, even before starting thinking about if its mathematical formulation gives rise to affine constraints, norms, etc. And I mean more than in a sense greater than by the experience (gained from this course for example) that many problems in finance, estimation and so on may be formulated as convex problems.

Or does the problem really needs to be formulated in a somewhat mathematical sense before it makes sense to talk about convexity? A bit philosophical perhaps, but I would be interested to know your thoughts about it :)>
114:<Hmm I managed to convert the problem to a convex one in the same way as paltahasan, but obviously with the same result because the alternative version is not actually equivalent.

I understand that the problem is quasi-convex, and that I should be able to solve it with the method of p145 in the lecture notes, but then I still need an appropriate function $phi$ - and this I find a bit more difficult. I read §3.4.5 and also found that in example 3.32 the convex sublevel sets for a linear-fractional function are given. However, I'm not sure what happens to the sublevel sets when I take the max abs (or the equivalent L-norm).

Am I missing something? Am I thinking in the wrong direction? Any guidance is appreciated :)>
115:<Yes, CVX is magic. :)

In my experience, it was quite liberating to realize that the meaningful distinction is not analytic (pencil-and-paper) solution vs. no solution but rather computable vs. not computable. It seems like you are experiencing the same feeling.>
116:<@MicheleZaffalon LOL! Not tonight! :P>
117:<On a serious note, the answer to your question is yes. BUT - this yes comes with lots of experience, and from knowing the 'atoms' first. And how do we know the atoms? Through the math. 

But honestly, this is no different that how you learn a language. When you pick up a newspaper, the words just fly out in front of you. You just 'get it'. You dont have to parse each and every _letter_, because you use 'apriori' knowledge about letters, how they are configured, things you have seen before, etc etc. And how did you get that? From learning the atoms - the "math" - in kindergarten. 

Remember, that there was once a time when you did parse letters, and when you saw the word "Cat", and had to say "C".... ok this looks like a umm.... oh oh! "A"...and hm, this thing with a dash... oh thats a "T"! So wait its ..C...A...T.. oh, A cat! Meow!

There WAS a time when we all did this with almost everything. But because we did it 'the hard way', when we are grown up, we can just look at a wall of text and 'see' words so seamlessly you do not even realize it. 

For me for example, I am currently in Convex Optimization Kindergarten, because I am going at my own pace, but also because I am doing exactly this "C...A....... oh oh! T" business on my own. So it takes me a loooooooooong time to parse things, and when I get stuck I ask here or on stack.exchange, etc. But I know that after this 'kindergarten', I will graduate, and 'know' that log-sum-exp is convex, and that log is concave, and I will one day see a convex function as an argument to another convex whos extended value is not non-decreasing and hence know that the result is convex. :-) Why? Because like language, we have to parse it very very slowly in the beginning, and then it becomes SO much easier. 

This is why I am actually going on my own pace. You will get there! :-)>
118:<My plan is to finish learning Chapter 3! :P>
119:<That's probably and even better option :)>
120:<I like your plan (and have a similar plan)... :-)>
121:<Your text made me smile. :-)>
122:<I had independently reached the same conclusion. Happy nobody was asking for a response to 3 or 4 significant figures :D>
123:<@demue Thanks! Its the truth. :-)>
124:<Thank you. You're right, I could find all the deadlines regarding the past weeks, but this week's is missing unfortunatelly. We've got plenty of new materials, enough for two weeks :).  I do not know when will the course end.>
125:<I think they will be offered in future but not this year. 
Thats why cvx has 101 with it. :)>
126:<Hi,
I used toeplitz funtion and it works :)>
127:<Same here, I just posted separately about it - my search did not find me this page :)>
128:<But in principle minimizing the root of a sum of squares (L2 norm) should be equivalent to minimizing the sum of squares itself, no?

Cihan, that indeed still seems to be a bit of a challenge :)>
129:<@Tcubed: I know it's the truth.. that's why I smiled! But if this is "convex optimization kindergarten," I cannot wait for "convex optimization highschool" and "convex optimization university." :-)>
130:<I think the staff said that they have no plans to offer another MOOC this year.. But this doesn't mean that they won't offer EE364B next year. (I hope we'll see a sequel to this course). :-)>
131:<You are right, Samvh. The circle should pass between the points like you said. I made a few changes to my code and get a circle better than the one I got from just constraining them within the circle. Like what we do in linear classification, I add a slack variable u(n,1) to my objective and constraints which allows some points out of the circle. The objective function is like R+lamda*1'*u and for each point I restrict the euclidean norm(i.e. the distance) between it and the center less or equal to R+u(i,:). After fiddling with lamda for a few times and I get a circle that looks alright.![enter image description here][1]


  [1]: https://edx-west-uploads.s3.amazonaws.com/1<phoneRedac><phoneRedac>83.png>
132:<@demue Yes, sorry! I didnt mean to imply you didnt know that! :P You know, the funny this is that I do believe that this book actually has Convex Optimization from KG all the way to Highschool. Not every chapter is created equal in my opinion. For example I think Chap-1 is pre-school, and chapters 2-3 are Kindergarten. In fact, I would be content with just going through and completely understanding every last corner of Chap2-3 before moving on. (That is what I am doing in fact). I want to be able to "Look-Read" a problem, like I do a newspaper. :)>
133:<"...or in economics, the sign is suspect."

Well said :)>
134:<@TCubed: I know that you know that I know... :)

I think that some chapters are more "difficult/advanced" or simply contain much more information than other chapters. 

Sometimes I can read 10-15 pages at once but then I have to stop and one example (problem) requires me to invest 2 or 3 hours just to understand it. 

I'm more into pure math. Sometimes I sit here while reading the cvx book and have to derive something which would be rather obvious to an engineer. On the other hand I didn't have any problem with the "theoretical" stuff (convex sets, functions, duality, algorithms, etc). But the examples keep killing me. I find Nemirovski's books much easier to read. The level of difficulty stays the same from page 1 to the end.>
135:<thank you very much ... it's clear now :-)>
136:<I struggle with this problem until my mac running down of battery.I still get "Status: Failed ,Optimal value (cvx_optval): NaN".I am not sure my solution has any problem.This is a slice of my code:<br/>
variable p(n,n) <br/>
maximize sum(sum(p.*idx))<br/>
subject to<br/>
        sum(p,2)==p1';
        sum(p,1)==p2;
        p>=0;
        sum(sum(p))==1<br/>
where p is joint probability,idx is index matrix where the element is 1 if R1+R2<=0,p1 is marginal probability of R1 and p2 is marginal probability of R2.correlation coefficient ? is not used in this solution.Please help me figure out my issue.Thank you!>
137:<Kind of ironic given the grader accuracy issues :)>
138:<I went ahead and did my second submission.  Should have read the note below first :)  I think they truncated to two digits, and rounding to two digits gets the wrong answer on both.  Oh well.  Gipped on this quiz as the problem set IS wrong.  I expect a reset and verification of rounding or truncation of answer.  Anyone listening out there?  This is marked up as high as it gets, and NO response yet.  It's bad enough that we are debugging these egregious mistakes...>
139:<first of all: catch up again, since I had to take a short break ( too many exams, but now I'm free ! :-) )

Then 364b, I really enjoyed this course. It's so amazing that this fantastic lectures are all availably for free.
Tomorrow there'll start a discrete optimization course on coursera and I want to learn more about statistics and probability ( my background there is quite poor ). What I also really enjoyed is cs364 (-> youtube), since there is also 'a' and 'b' and I'm only half way through 'a' I think I'll have a wonderful semester break :-)>
140:<The discrete optimization class is fun but it's a tough class. I tried to do it last time but didn't find the time to finish it. The course page is true when it tells us that we have to invest 10-20 hours per week. Maybe I'll give it a try, though I'm already enrolled in numerous other classes (cvx, functional analysis, two philosophy classes and statistical learning).

Which exams did you have? I hope everything went fine for you! :-)>
141:<That definitely gives it away. Not complaining or anything :)>
142:<Yes, I know that. I'm waiting for this class to start for about half a year and many people have already warned me. Hope to see you there :-)

How is functional analysis and do you know when it'll run again? Just out of curiosity, which philosophy classes are you taking?

The exams were -I hope- ok. ….anyway they are over now:-)>
143:<I wonder if anybody else has observed this problem:<br>
Solving the Worst-case probability of loss problem from the Stat. Estimation HW set, my code will run without warnings and return the correct result if I use the sdpt3 solver (i.e. issue the command `cvx_solver sdpt3` before calling CVX), but if I run the *exact same code* using Sedumi (i.e. `cvx_solver sedumi`) I get <br>

    No sensible solution found.
and

    ------------------------------------------------------------
    Status: Failed
    Optimal value (cvx_optval): NaN

Here's the code, if someone wants to confirm my observation, and/or maybe find an explanation:

    %%
    m1 = 8; m2 = 20; s1 = 6; s2 = 17.5; rho = -1/4;
    n = 100; rn = linspace(-30,70,n)';
    p1 = exp(-(rn-m1).^2/2/s1^2);
    p1 = p1/sum(p1);
    p2 = exp(-(rn-m2).^2/2/s2^2);
    p2 = p2/sum(p2);
    %
    i0 = bsxfun(@plus, rn, rn') <= 0;
    % i0 = 1 for indices where r1+r2 <= 0, 0 else
    % so prob(r1+r2<=0) = sum(Psi.*I);
    %%
    cvx_solver sdpt3    %<-- result matches the grader's with sdpt3
    % cvx_solver sedumi %<-- result is garbage with sedumi
    cvx_begin
        variable Psi(n,n)
        maximize( sum(sum(i0.*Psi) ) )
        subject to
            Psi(:) >= 0;        
            (rn-m1)'*Psi*(rn-m2) == rho*s1*s2;
            %   vv-- equiv. to line above
    %       sum( sum(Psi.*((rn-m1)*(rn-m2)'))) == rho*s1*s2; 
            Psi*ones(n,1) == p1;
            Psi'*ones(n,1) == p2;
    %         sum(sum(Psi)) == 1; % <-- spurious
    cvx_end>
144:<This is the solution I used, and got the right answer.  Basically least squares fit the data, and the censored data together.

    cvx_begin
        variable c(n)
        variable yc(K-M)
        minimize ( norm([y;yc]-X'*c,2) )
        
        yc>=D
    cvx_end>
145:<Hi, 

Apologies in advance if I give away too much information. 

I have obtained a solution to this problem to 4 significant digits after decimal. I have checked the answer (since my solution is rejected as incorrect) and found that it is also given as 4 significant digits after decimal, and surprisingly only the second digital after decimal is found to disagree between mine and the grader. 
That is, mine: a.bcde, the grader: a.bfde
Is there a hope that the grader is incorrect and I am correct ? :D 
I have plotted my fitted circle and it looks nice, and my problem formulation is the simplest. 

Thanks

<nameRedac_anon_screen_name_redacted>>
146:<clear all
    clc
    
    k = 201;
    t = -3 + 6*((1:k)-1)/(k-1);
    t = t(:); % column vector
    y = exp(t);
    
    % below range is obtained after multiple searches over higher ranges
    z_vec_dB = -16.5:0.05:-16; 
    z_vec = 10.^(z_vec_dB/10);
    Feasible = zeros(size(z_vec));
    Objective = zeros(size(z_vec));
    Results = cell(1,length(z_vec));
    
    for zId = 1:length(z_vec)
        z = z_vec(zId);
        cvx_begin
            variables a(3) b(2)
            minimize 0
            subject to
                [ones(k,1),t,t.^2]*[1;b] >= 0  % denominator is non-negative
                [ones(k,1),t,t.^2]*a - [y,y.*t,y.*t.^2]*[1;b] - [z*ones(k,1),z*t,z*t.^2]*[1;b] <= 0
                [ones(k,1),t,t.^2]*a - [y,y.*t,y.*t.^2]*[1;b] + [z*ones(k,1),z*t,z*t.^2]*[1;b] >= 0            
        cvx_end
        % make sure that the positivity of denominator is satisfied along with
        % the feasiblity condition
        if strcmp(cvx_status,'Solved') && all([ones(k,1),t,t.^2]*[1;b] > 0) 
            Feasible(zId) = 1;
            Objective(zId) = max(abs(([ones(k,1),t,t.^2]*a)./([ones(k,1),t,t.^2]*[1;b]) - y));
            Results{zId}.a = a;
            Results{zId}.b = b;
        else
            Feasible(zId) = -1;
            Objective(zId) = Inf;
            Results{zId} = [];
        end
    end
    
    DataIds = 1:length(z_vec);
    figure
    plot(z_vec(DataIds(Objective ~= Inf)), Objective(Objective ~= Inf),'-b*')
    xlabel('z ');
    ylabel('Objective function value');
    
    % get the min value
    [min_val,min_id] = min(Objective)
    % coefficient vector a
    Results{min_id}.a
    % coefficient vector b
    Results{min_id}.b>
147:<It has been a really nice course. Thanks to Prof. Boyd and his team. :) <br>
I guess we can help by suggesting improvements to make this a better place to learn. 
Feel free to post your suggestions.

Thanks,<br>
<nameRedac_anon_screen_name_redacted>>
148:<whaaoo!! :O :D>
149:<I agree with both the original poster and Dennis/demue's answer. The stopping criterion in question is very "reasonable" [I made that "mistake", too, twice :)] albeit not "practical" or "useful" in most cases (Dennis gives a nice explanation). Additionally, one may also argue [here comes my second "mistake"] that the second stopping criterion (vanishing norm of gradient) has the potential to neither be reasonable nor useful, in general, as it requires the objective function to be differentiable at its minimum. While satisfied in many cases, for example, this stopping criterion would fail for a simple unconstrained convex problem like $min lvert x vert$ over the real numbers.>
150:<@demue Ah interesting! What book is that from Nemirovski? 

Yeah, I spend a LOT of of time un-compressing the examples from A to Z. I have to. I dont feel good if I do. I think a good book would be one that is uncompressed, esp for kindergarten phase. 

I am certainly learning a lot though... though at my own pace... :)>
151:<And with very easy to keep track, I mean lose track. :)>
152:<To point (1), the book does have many more theoretical exercises after every chapter to test your knowledge. To me, the course in the current format (biased towards applications) is perfect. I can almost immediately apply it to my work. 
There are a lot of either "theory heavy" math courses or "programming with a library/package" courses but very few like this one that is in the sweet spot of applied theory :)>
153:<i too got it correct.
http://scholar.harvard.edu/ntenenholtz/blog/2012/11/model-fitting-using-least-squares
this link helped me a huge lot.
try u guys too
:)>
154:<No help yet so I just plod along. There must be an easy way to see this but I can't. If I try to solve this for the general quadratic norm $left | x ight |_P$ it looks like:

$Delta_{nsd}=argminleft{
abla f(x)^Tvmid (v^TPv)^frac{1}{2}=1ight}$

so to just pound through it:

minimize $
abla f(x)^Tv$ subject to $(v^TPv)^frac{1}{2}leq1$

$L(v,lambda)=
abla f(x)^Tv+lambdaleft [(v^TPv)^frac{1}{2}-1ight ]$

$frac{partial L}{partial v}=
abla f(x)+lambda (v^TPv)^{-frac{1}{2}}Pv=0$

$frac{partial L}{partial lambda}=(v^TPv)^frac{1}{2}-1=0$

solving for $v$ gives

$v=P^{-1}
abla f(x)(
abla f(x)^TP^{-1}
abla f(x))^{-frac{1}{2}}$

Then substituting $P=
abla^2 f(x)$

$v=alpha(
abla^2 f(x))^{-1}
abla f(x)$

$alpha=(
abla f(x)^T(
abla^2 f(x))^{-1}
abla f(x))^{-frac{1}{2}}$

Surely there is an easier/clearer way to do this (and I seem to have lost track of a minus sign somewhere along the way...)???>
155:<Let's hope this is gonna happen,love more excise though :-)>
156:<I hope they'll be 'optional' exercises! :-) Probably I won't have much time to work through the material on interior point methods but I'd love to come back later and do the homework.>
157:<me 2 :D>
158:<Something that screwed me up on my first try is that if you do a condition P >= 0 this means every element of A must be greater than 0. Obviously that's not what I wanted :).>
159:<Yes, I have also noticed the Gamma function. :) Thanks for your reply!>
160:<Actually, I have a model which includes the log(Factorial(continuous variable)) function. So if I want to use CVX to solve my optimization problem, I think I have to do exactly what you suggested. Thanks for your reply! If I get some progress, I'm glad to share with you. :-)>
161:<Good one: red button :))>
162:<@spatry: I agree with the rough understanding and I would add some abuse of notation :-)

By the way, I think my comment was not relevant.>
163:<Another piece that took some figuring for me is that the preferences array is a list of indexes which people like column 1 more than column 2, look at the data generation code.

    % %coherent preferences
    % for i=1:numpref*.9
    %     ranking1=map_object_to_ranking(objects(i,1));
    %     ranking2=map_object_to_ranking(objects(i,2));
    %     if ranking1 < ranking2
    %         preferences(i,:)=[objects(i,2) objects(i,1)];
    %     elseif ranking1 > ranking2
    %         preferences(i,:)=[objects(i,1) objects(i,2)];
    %     end
    % end>
164:<Awesome discussion gents. I have been scratching my head last 1+ hour trying to figures this out. If not for this discussion, I would have lost a lot of sleep :-). This thing seemed so fundamental to the classification problem.

In general, as a working guy with limited time, I am finding this course way too hard :-). Is it only me, or are there there others who feel that Prof Boyd could go a tad slower :-). And this is not a whine or a complaint, I respect his brilliance. But I feel if he were to go slower, it would make it that much more of a pleasure to understand and digest all the concepts, at least for me :-).

Cheers
<nameRedac_anon_screen_name_redacted>>
165:<:-) …wow. well, i still haven't looked it up but that's good to know.>
166:<Actually this is a pure LP problem, I solved it without using CVX, back-slash in matlab is enough:)>
167:<On this [thread][1] a staff member said they were not planning to offer another MOOC this year. I think it's unfortunate, it would amazing to have Convex Optimization II here on EDX, so I hope they will change their mind :)


  [1]: https://class.stanford.edu/courses/Engineering/CVX1<zipRedac>1/Winter2<zipRedac>14/discussion/forum/i4x-Engineering-CVX1<zipRedac>1-cvx/threads/52fd<zipRedac>d1a2511f6e52e<zipRedac><zipRedac><zipRedac><zipRedac>21 "thread">
168:<March 16, look course info :)>
169:<Using a different set of maximum rates will give a different value of lagrange multipliers. Some max rates are 100 and so it doesn't look like the growth rate is affected by it at all. 
If all of them are capped to the same value, then we can see which reaction the growth rate is most sensitive to. At least that is my explanation for the unexpected answer :)>
170:<It is not. It is mentioned "our expression should only involve the symbols f, s, n and m" :) Yet still there is something wrong with the grader>
171:<Yep, that last problem was fun. Took me 2 hours, but I solved it. :)>
172:<@Samvh: You didn't write $P^	ext{max}(i+1)=P^	ext{max}(i)*p_j$ because this would be wrong: there could be a path that takes you to node $i$ with probability $1$, there could be a totally different path that takes you to node $i+1$ also with probability $1$, but there could be no edge between $i$ and $i+1$.

So what do you mean exactly with some function of $p_j*P^	ext{max}(i)$?>
173:<Try to think the problem as assigning different "potentials" (a function of the different $P(i)$ as suggested here above)  to every node. The first node has zero potential and the other ones are constructed in order to get the optimal path. The condition to have the optimal path is this:

> For any edge $j$, the difference between the potentials of the two adjacent nodes $k$ and $l$ is bigger or equal to the weight of that edge (in this case it is also a function of the real weight according to the same transformation used for $P(i)$). 

The inequality makes the path optimal because if the condition was not satisfied, it would be better to choose the path that passes through that edge $j$ making the inequality tight for that $j$.

Finally, minimizing the potential associated with node $n$ (we want to solve a minmax problem) with respect to the  variables 

 - vector of "potentials" 
 - vector $x$' 

and subject to the constraints:

 - The one explained above
 - The potential of the first node set to 0
 - The ones for vector $x$

gives the right solution for the first part. For the second part it is necessary to solve the same problem only with respect to the vector of potentials and with $x$ as a parameter given by the uniform allocation of resources. 

I hope it helps :)>
174:<You want to maximize the likelihood of your estimated a's corresponding to the outcome of the games. So if team $i$ wins a game from team $j$, ideally $a_i$ would be higher than $a_j$. However, just as with the ranking problem last week, you might not be able to do this consistently, so you want some overall optimum. Note that the distribution of outcomes when team $i$ plays against team $j$ is normally distributed, so when you want to calculate the likelihood (probability) of team $i$ winning based on values $a_i$ and $a_j$, you need to take this into account. Luckily the exercise provides a hint as to how you would accomplish this ;)

Also think about how you can use the $A$ matrix and your vector of $a$'s to describe the likelihood of the observed outcome of each game.>
175:<Thanks for the hint. I've had a similar issue and this is quite enlightening  :)>
176:<Thanks.  :)>
177:<actually you method was correct, i got the answer through that, simply no need constraints, i just changed my objective to sum_square_pos(v), inequality given in included in our objective. :)>
178:<Actually, the ***A*** matrix is not needed :)>
179:<$y(i) = 1$ when $P(a_j - a_k +v >0)$, and $y(i)=-1$ when $P(a_j - a_k +v < 0)$. Each of these two probabilities can be expressed in terms of the normal CDF function. Collect all the probabilities for which $y(i)=1$ and all the probabilities for which $y(i) = -1$, and take log. This is your likelihood function that you are asked to maximize. Hope that helps :)>
180:<Sidereus, you are worth your nickname. Your hint  at a potential (coming from stars indeed :) ) was crucial for me. Thanks a lot.>
181:<Actually, you can write the objective function in literally one line if you use just the `train` variable. I found the variable ***A*** more nuisance than anything :D>
182:<are you doing something like this?

    cvx_begin
      variable R_square(m)
      minimize(L'*R)
      f = alpha.*R_square.*(-A'*h)./L;
      -A(1:k,:)*f <= Smax
      -A(1:k,:)*f >= 0
      A(k+1:n,:)*f >= max(C, [], 2)
      R_square >= Rmin.^2
      R_square <= Rmax.^2
    cvx_end>
183:<@rannavajjala It will be really nice if you can post your code after the deadline. :)>
184:<@Samvh: I am sorry if I have over-claimed anything in my formulation. I also need one line for cvx variable that I want to optimize over, and one line for the objective that I am optimizing, and in fact two lines for the upper and lower bounds on the variable $mathrm{a}$. I am only saying that the objective function can be written compactly using the variable `train`. 

@chengzhang: Yes, more than happy to post it. 

In fact, my brain is not yet fully developed to process the sparse matrices. So, by all means, I am avoiding them :)>
185:<@rannavajjala: I understood that you just meant the objective. You can use lower_bound <= a <= upper_bound in CVX - saves you another line next time ;) And if you don't like the sparse representation in matlab you can use the full() function (for display purposes, I imagine that the value of $A$ passed to CVX is intentionally in sparse format).>
186:<Perhaps someone can give me a hint.  I keep having problems with my setup, probably because my constraints are not set up right.  I have the following constraints:

      logpnode(n) == sum(logpnode(1:n-1)) - a(n) * x(n) 

which (I think) will find the log(P(i)) vector, and from which I can get Pmax since log(Pmax) = log(P(n)).  (Note that I maximize logpnode(n) as the objective).  What I struggle with is to ensure I only consider valid paths in the problem.  I assume this must involve a constraint that includes A * (a .* x) but it's not obvious to me what the other side of that constraint should be.  Can someone provide a hint?  Am I approaching this the right way? 

Thanks a million!  :)>
187:<Over a two-hour period on one morning this week, I thought this is going to a rotten egg :). 

This is a positive number, bounded from above!>
188:<Appreciate very much for this explanation. This is one of the problems that I got wrong. Nevertheless, I learned something in this thread :)>
189:<Also, you might be confusing people by using $x$ as the path variable, since the problem also has $x$ as the effort allocated to the edges. I think you meant $A*p=b$ where $p$ is of length $numEdges$ as you have above. I think it's great that you worked out some examples to get an intuition for the constraint. I did the same too. =)>
190:<The "correct" answer simply states that the growth rate is most sensitive to itself. An information that is practically useless. Also you can't just change vmax, this would amount to changing the problem, i.e. the answer you get would not apply. As none of the 3 non-zero Lagrange multipliers is particularly large (or small) compared to the other, I had to test how sensitive v(n) was to each. The only non-zero Lagrange multipliers where y(1),y(3) and y(5) (y the dual of v<=vmax) - which correspond to: R1: extracellular-->M1, R3: M1-->M3 and R5: extracellular-->M5. This makes perfect sense since R1 and R5 are reactions that absorb mass (okay I'm not a biologist) within the cell - a perfectly reasonable way to increase the biomass. Another candidate would have been R8 which expels mass from the cell, but its Lagrange multiplier is zero hence this constraint is slack. After testing y(1),y(3) and y(5) the result was that the problem was most sensitive to y(1), by far. 

Okay, they made a mistake - so what? These scores don't count for anything and to be honest I found that identifying the mistakes in this course was the most fun part of it - welcome to reality :)>
191:<agreed :)>
192:<The March 15 post on the 'Course Info' page says that the course materials will be accessible online "for as long as you'd like" :-)!>
193:<I find you everywhere.. :D>
194:<I too want to thank the Staff for this amazing course.
This MOOC was absolutely fantastic!

Especially I want to thank Prof. Boyd for these wonderful lectures. Your crystal clear and humorous teaching style was really impressive!
And I want to thank the TAs and the Staff for their friendly help in the forum and the organization of this course.

This course was a wonderful learning experience and i enjoyed every minute :-)>
195:<Hmm great course.. I enjoyed all the video lectures which contains nice recipes of various mathematical stuff. Mr Boyd also gives some intuitions and glimpses of relevant stuff during his lecture. I should have maintained a running notes while watching the videos for quick access of the important points, even though I downloaded the videos. This course made me to reform myself as I was before a few years back (like in cricket coming back to form) :). Finally I want to add thanks to Mr Boyd and the course team and my fellow takers.>
196:<:D thanks!>
197:<You are right. When $k=1$ or $bin R$, it is not hard to make the denominator terms common and find that there is only one $x>0$ that makes the $f'(x)=0$. But in my case I don't know how to make the denominator terms common when $b in R^{4}$.

I have to say I didn't quite understand the details how you make denominator term common.
>>"i.e. split each bj into bj.b where b is common) bTx will come out bjT1 will be inside"

Could you please illustrate it a little bit? Many thanks! :-)>
198:<Great course and one of the best MOOCs I've taken so far. 

I didn't find the time for the last 2-3 weeks but it was a fun journey. I've already starting watching the first videos of EE364B. 

I hope there will be a CVX102. The discussion forum for this course was and is awesome. It's fun to learn the material in a MOOC setting. :-)>
199:<@asadhasan: I have fixed my code, I got the correct result, and I can defend my approach :). Here it is: 

    cvx_begin
        variables x(m) LogP(n)
        minimize (c'*LogP)   % = LogP(n)
        subject to 
            ones(m,1)'*x <= B
            x <= x_max
            x >= <zipRedac>
            LogP(1) == <zipRedac>
            for nodeId = 2:n
                EdgeList = find(edges(:,2) == nodeId);
                SourceNodeList = edges(EdgeList,1);
                % max of P_prev = P_current implies each of P_prev =
                % P_current
                LogP(SourceNodeList)-a(EdgeList).*x(EdgeList) <= LogP(nodeId);            
            end
    cvx_end
    disp(['P^{max,*} = ', num2str(exp(LogP(n)))]);

The optimum value is: <zipRedac>.<zipRedac>43284

Note that the earlier equality constraint is replaced by the inequality constraint. This makes perfect sense (**and the right thing to do**) since $P_j = maxleft(P_i e^{-a_k x_k}ight)$, where $k$ is the edge from node $i$ to node $j$, implies that $P_i e^{-a_k x_k} <= P_j$ $forall,, i < j$.>
200:<@rannavajjala: We are trying to take steps towards clarity, so your redirection is helpful :). The more one thinks about these things, the more concepts solidify!>
201:<Yeah.. in my second comment I corrected myself, as we cannot take the denominator common. But lets start like this. Any function which first increases and then decreases will be a quasi concave. Here functions under sum i.e. log(ai'x)/bi'x fallows such property and are also differentiable. So here when we take sum of such functions (for simplicity take two) such property seems to be preserved i.e. first increasing and then decreasing. If we try to plot two individual functions they would intersect only once (not tried in detail) which preserves the single local maximum point. This can also be visualized under plot of its derivative, which crosses the x-axis only once and approaches to zero at infinity (even in this plot they tend to intersect only once). Note that I am not 100% sure but if we prove this algebraically (either one of these: only one solution for phi1(x) == phi2(x) or phi1'(x) == phi2'(x)) we are done. And yes its quite interesting :)>
202:<Thanks to Prof. Boyd and his team for an excellent course.  

I learned a lot and in particular (and to my surprise), I learned that a whole world of challenging problems can be (fairly easily) formulated as convex optimization problems.  This is eye opening to me as previously (and due to my ignorance), I perceived such complex problems as just overly complex and requiring a lot of special coding to work out an acceptable solution, whereas in fact, they can simply be formulated as a set of constraints and a simple convex objective function.  This is an awesome discovery for me!  :)

Again, many thanks to the team for providing such a great perspective on how to approach problem solving of complex applications!

I look forward to taking the next course when offered!>
203:<I have the same problem. This is my 1st MOOC too. I thought it is something like a letter or a certificate they are posting for each of us. Dont know exactly. Like to know about it further :-)>
204:<i just saw the email, they have said that it is a pdf that we are able to download from that dashboard directly by monday onwards :-)>
205:<Interested. :)>
