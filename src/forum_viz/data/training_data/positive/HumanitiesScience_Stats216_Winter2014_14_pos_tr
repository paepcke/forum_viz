0:<No, definitely assume a uniform distribution.  I'm a TA =)>
1:<Hi, 
This is Seema Sangari here, taking classes online. I am Comp. Sci. graduate with double masters in finance and applied statistics. I work for IBM in Business analytics mainly focusing on Risk area. Please feel free to get in touch over linkedin.
Hope you are enjoying the course, I am definitely :).>
2:<Thanks Seema. I'm just a little bit confused about predicting the number of applicants by using the number of accepted and enrolled :)>
3:<Is there any difference between

lm(response~pred1:pred2)) and lm(response~I(pred1*pred2))>
4:<The standard error refers specifically to the standard deviation of an estimator.  We say SD for a general random variable, and SE for an estimator (which is a specific kind of random variable).  And no, I don't know why we need a different name for that :)>
5:<That's because the question was copied and pasted out of the book :)  Sorry about the confusion!>
6:<I am showing my age. http://en.wikipedia.org/wiki/Transparency_(projection)  Wikipedia explains how we use to use transparency foils to share information.  We considered them a huge upgrade from our previous information sharing methodology...cave drawings!!! :)

I mean page 38 (32 and 39 also).  I see equation 2.7 in Chp 2 of the book.  It seems to me to actually compute the bias, you would need to know the true relationship between Y and the X's and to calculate variance, you need test sets.  So I am interested in the work behind the scenes it actually took to create those graphs.>
7:<No, you are showing your quirky foreign upbringing.  In Amurrca we call them "slides," also a holdover from that bygone era.  Rob (Canada) and Trevor (South Africa) were also brought up speaking non-standard English and we ridicule them constantly :-P

You are right that the bias depends a great deal on the true beta.  If beta = 0 then we <nameRedac_anon_screen_name_redacted> incur no bias at all.  The plots you're looking at are coming from simulated data, meaning that (unlike in the real world) we actually get to know the true values.  Otherwise we could not know the bias, or the MSE, or the irreducible error.

For ridge regression, $hat y_lambda$ is a linear function of $y$ so we can compute its expectation, and the bias, exactly.

More generally, we can just simulate many times and apply our procedure to every data set, then compare the predictions to the true means (if the true means are known)>
8:<I also happened to come across this article today via twitter, and found it interesting. The article would have never drawn my attention had I not been taking this course... :) I certainly am not knowledgeable enough to make any sensible comment, but putting aside the latter part of article about "p-hacking", while the article focuses on p-value, if I am not mistaken, wouldn't it be possibly due to more of adequacy of designing statistical models, including things such as constructing adequate hypotheses, possible overfitting, wide gap between training MSE and test MSE, etc., because p-value appears an outcome out of those...? Or is it indeed the validity or "misuse" of p-value as mentioend in the article..? It would be great to have some comments from the professors and/or TAs.>
9:<thanks. I couldn't see the random forest for the decision trees. :-)>
10:<Google PDF merge, there are a bunch of websites can do it online:)

Thanks,
<nameRedac_anon_screen_name_redacted> <nameRedac_anon_screen_name_redacted>>
11:<Craig,

In each iteration, you generated a new training set, right? I used the following:

x_0 <- rnorm(50, mean=0, sd=diag(10))
x_1 <- rnorm(50, mean=mu, sd=diag(10))
y_0 <- rep(0, 50)
y_1 <- rep(1, 50)

and then constructed a data frame.Did you have something similar?


Thanks.>
12:<knock yourselves out:   http://www.spreadsheet-sports.com/2014-ncaa-mens-basketball-game-results-data/  - remember to throw a little tip my way for this help if you do win the $1B  :)>
13:<Hi Vcologlu,

Once you obtained the principal component did you do something like this in regression for the R Code:
lm.fit=lm(y~pc1+pc2+pc3+pc4+pc5,data=dat)
to obtain the MSE test set ?

where y is the rbind of y and y.test?

Not sure if this is the right direction.

Thanks>
