0:<Hi everyone! I'm a high school math teacher. Last year I was given the chance to teach AP Statistics. I'm hoping this course will help me make my Stats class more interesting. :)>
1:<Hi I am <nameRedac_anon_screen_name_redacted>, and am pursuing my undergraduate studies in zoology.Since my course has a paper on maths and stats it will be very helpful for me to utilise my vacations in such an interesting course which will also be helpful to pursue my studies in Genetics in my masters and post doc. level!! 

Seeing many fellows from the medical and biotech fields, hope we all have a healthy interaction and learn from each other! cheers and all the best! :)>
2:<Hi, everyone ;) I am <nameRedac_anon_screen_name_redacted> - a hematologist-to-be. I entered this course, because i need more profound understanding of managing data in order to be successful in my PhD Thesis.
Greetings from Plovdiv, Bulgaria!>
3:<YOU ARE WELCOME :)>
4:<Hi :)
I'm <nameRedac_anon_screen_name_redacted>. I'm medical student .
I hope we all get best out of this course .>
5:<I'm a psychologist by trade (graduating in July). I'm interested in this because statistics feature heavily in my work and it's good to take a different perspective on that. :)

I'm glad I'm not alone!>
6:<Hi! I am actually a pre-medical student completing my bachelor's degree! Nice to meet everyone! :)>
7:<agree with you :)>
8:<from 

http://www.purplemath.com/modules/boxwhisk3.htm 

[quote](Why one and a half times the width of the box? Why does that particular value demark the difference between "acceptable" and "unacceptable" values? Because, when John Tukey was inventing the box-and-whisker plot in 1977 to display these values, he picked 1.5×IQR as the demarkation line for outliers. This has worked well, so we've continued using that value ever since.)[/quote]

I'm sure there's a really good calculus reason he decided on 1.5 when he invented it :)>
9:<Here is an example of medical jargon, I would have said that "Age at first birth" is a unary variable whose value must always be 0  :-)>
10:<thanks for the link 

I didn't understand it, but like you said, probably need a little more understanding of the normal curve

I've bookmarked it and will revisit in a week or two :)

thanks again>
11:<Of course. That would be great! :-)>
12:<Hi everyone . I am <nameRedac_anon_screen_name_redacted> and I am a clinical Pharmacologist.Hope to refresh Statistics which I had learnt earlier :)>
13:<Yes, this is the age of the mothers at their first birth!  :)>
14:<Now I got it :) Above the video window, you will see an icon of a text document-this is the link to the quiz. The moment your arrow is on the document you will see the text "quiz" appear.
I hoped it was helpful for you Nusrat!>
15:<it is my first time to learn course online in a big famous university like STANFORD UNIVERSITY  , Thank you very much guys , i am so happy :)>
16:<The question was not phrased properly, i guess. The skewness is not connected with the relationship between the mean and median: a distribution with negative skew can have the mean greater than or less than the median, and likewise for positive skew.

"Always" is wrong: take for example the data {1,1,2,2,3} which has a mean of 1.8, a median of 2 and a positive skewness.

But more typically, negative skewness is associated with some extreme values below the median and fewer or less extreme values affecting the mean. These will typically push down both the skewness and the mean.

correct me if i am wrong :)>
17:<Yes, try another browser and see if that helps.  
I'm using Chrome on Windows and both EdX and Stanford work like a charm.
So try Chrome or as mentioned above Firefox and see if that solves the problem :)

If not, you can come back here and we can see if we can find a solution. I might not know much about statistics, but I know at least something about computers ;)  
Oh, if you still can't fix it, don't forget to mention your operating system and browser(s).>
18:<Thank you :)>
19:<Thank you :)>
20:<I hope that find a solution! :)
I use Windows, with Chrome and Firefox.>
21:<If you get the feeling that there should be an easier way to do something in R, there *always* is. It's up to you to decide whether it's worth your time to hunt for a more efficient way (stack overflow will have an answer to just about anything you type into a google search), or whether you're happy to use something that's working for you :)

A lot of the *easier* ways of doing things come from programs that people have written called r packages. You can use their shortcuts by installing then loading their packages and learning how to use them, so the shortcuts are not always so quick.>
22:<Unit 1 homework ;)>
23:<By the way where is the submit button on homeworks. Moreover, what is the purpose of Final Check and Save. I am afraid of using them so that my attempt is not lost. Sorry if it is too childish a question:)>
24:<You outlier  :)>
25:<well observed. :)>
26:<Students should get one free point for that :)>
27:<thanks; I'm asking if I'm looking for the sensitivity=P(55+/ankle fracture)?>
28:<Incidence explained as "20 new cases per 1000 men per year" is surely a rate. But the cumulative risk as "1% new cases over two years" - even though it's a percentage obviously the "two years" part means it's again a rate, so I'm confused.

Is it like speed and acceleration? Cumulative risk tells how is the disease spreading overall, while incidence tells the speedup of the spread - is that correct?

It's also hard to google out the terms - the only [other definition][1] I was able to find seems to equate "cumulative risk" and "cumulative incidence" but here it starts getting even more confusing! :)


  [1]: http://practice.sph.umich.edu/micphp/epicentral/cumulative_incidence.php>
29:<I did very poorly. Forgot how important order of operations is. Good thing one test score is thrown out. This was a learning experience for me! Happy Saturday :)>
30:<I agree about the races, Chooi.  I have decided that this may be a cultural thing in the States.  Here in Australia if you are 'not white' there are a lot of other races that you may be - Asian, Indigenous, Maori, Islander, Indian, Srilankan... 

As for the smokers section... 'not' currently smoking should include both ex- and non-smokers because by definition neither are 'currently' smoking.  But I do also see your point. :)

And Piyush... never assume! :) I would have loved to have seen the methodology section that went with this to find out what variables they were looking at - that would have told us a whole lot more. 

Rose>
31:<Does any kind soul (or /and including the course engineers) know how to download the .srt files (for the captions) This way we can have the captions for the videos in offline mode. I tried to capture the .srt files using a YouTube caption downloader plugin in Firefox but it doesn't seem to work :( . If the course engineers could put up the .srt files on the wiki we could download them for offline use and would be of great help especially when we speed up videos for say revision (as the voices become chipmunkish when speeded up offline :) ). Also since many of us (who are non Americans) find the American accent difficult to follow at times - we have to replay a section repeatedly sometimes to understand what a particular word or phrase meant and also at times some word  is just unfamiliar wrt usage - for eg "N's" I was not sure if I had heard it right as that was a usage I was not familiar with and then finally understood that as "Numbers" ! This will sort out a lot of confusion related to such issues.>
32:<Why do we multiply the IQR by 1.5 and subtract/add from Q1/Q3 to find the whiskers in a box and whisker plot? I understand that we use it to identify outliers but is there a reason why we use 1.5? Or has it just been arbitrarily chosen by someone way-back-when?

Thanks :D>
33:<Two :-)>
34:<Hello otini, I recommend you To review the formula and check slowly what you did wrong in the exercise. I could calculate it so try again. :)>
35:<I'll second the Final Check -> Submit button idea. :)>
36:<I really enjoyed this very interesting analysis of the lipstick "problem" :)
I would like to point out only a minor inacurracy in the slides (and the explanation) around minute 14: The average exposure to lead through lipstick is about 0.1% of your PTDI, not 0.2% as it is stated in the slide and commentary.>
37:<Thank you so much :)>
38:<LOL  The email indicates at least 5,700 so we should be here for a while.  :)>
39:<Dear all, I was unable to load the excel file and failed to install the XLconnect as well. 

It is out of my depth to understand the problem as shown.

Is there any kind soul that can clarify it for me?

Please help.

Thanks a lot in advance. =)

http://www.image-share.com/ijpg-2193-211.html

 ![Deducer's probelm][1]




  [1]: http://www.image-share.com/ijpg-2193-211.html>
40:<It is on the next page 'Exercise 1 Lab' at the top. You should see it with another button for downloading the MS Word file of questions :)>
41:<Great course! Thank you!!!
Greetings from Hong Kong :)>
42:<cool :)>
43:<This wasn't about multiplying, it was about subtracting.  The difference between .17 and .73 is much greater than the the difference between .1 and .4.  Not sure why you're pointing out what the factor is.  Are you working for Merck?! ;)>
44:<Are you the same person as our course director ? :)>
45:<Thank you very much Vippie =)

I have done as what you told me but still in vain.

The system replied with "error in extracting zip file"

I did try other countries as well but a window with a list which does not contain "XLconnect" keep popping up.

Eventually, I downloaded the xlconnect file from Cran and I am struggling to install it manually.

Could you please give me some guidance on this ?>
46:<James- Thank you for being awesome and sending me that link :)>
47:<I think it's because there were no control with no treatment. Your calculation assumes 0 heart attacks with no drug used, which is unknown and unlikely. Hope it makes sense :)>
48:<Thank you for setting up this course. Looking forward to learning on my mid-year break! :)>
49:<I asked some grammar experts and they said that using "next " is redundant. My US friends told me that they also have heard it being used but consider it as wrong usage :)>
50:<g.What percent of participants in the placebo group have hypertension?

Given figures are 2409/3258 (73.9) which I suppose means that 2409 subjects out of 3258 evaluated (which calculates to 73.9%) had hypertension.

However, the question asked about the placebo group (n=3281) and not about those evaluated for hypertension in the placebo group (n=3258). By easy observation, 2409 subjects had hypertension in the "placebo group". So doesn't it calculate out that (2409 / 3281 * 100 =) 73.4% had hypertension in the placebo group? Where did I go wrong? Please guide.>
51:<Thanks Sally! 

But suppose in a hypothetical situation in the placebo group, had only 100 people responded to the hypertension question and if all of them were hypertensives, the answers would have been 100% hypertensives in the placebo group? This would be quite misleading as would (100/3281*100=) 3.05% hypertensives in the placebo group. Wouldn't it be better if the question was set in a more accurate language? Or is this the standard phrase in statistics which although refers to the group as a whole but implies only the subgroup which responded?>
52:<Dear Mr Rajhansa, I have been sending the  .srt files to you so that they can be uploaded to the wiki (So far I have sent Unit 3,4,5 and 6). I am not sure if you are receiving them and I asked in an email  included with one batch of .srt files to kindly give me a reply so that I know they are reaching the receiver. I haven't got any reply so if Mr Rajhansa could confirm it I will be sure that I am emailing it to him rather than it being lost in some misty corner of cyberspace crying like a lost child for its recipient :) and the wiki cries -Where is my sister" ;)
Sorry but I think very "visually" even when I do my problems and that visualization of the wiki crying for its sister reminds me to email Rajhansa the .srt files when I finish downloading them..>
53:<Well, I can play that game too: those "experts" and your American friends are wrong :)

See how that doesn't work?

Anyhow, let me finish this off: "in this next module" makes explicit the fact that the module occurs in a sequence of modules.  Furthermore, it says that at least one module came before it and that at least one module will come after it.  "In this module" does NONE of that.  

You're welcome :)>
54:<Just wondering whether the exam will be timed or whether it will be similar to homework so we can take as much time as we like (within the time window that the exam is available for)?
Thanks :)>
55:<The cumulative risk for Vioxx is 0.42%, and for Naproxen it is 0.1%. So we can say that Vioxx is 4.2 times as risky than Naproxen, or, equivalently, that it is 3.2 times riskier than Naproxen.

Think about it this way: If the risks were 0.15% and 0.1% respectively, you would say that Vioxx is 1.5 times as risky, or 50% riskier. Notice that you get the second number (50% or 0.5) by subtracting 1 from the ratio (1.5). Similarly, in our case, we can say that Vioxx is (4.2-1=) 3.2 or 320% riskier.

Raj>
56:<Since beggars can't be choosers, maybe I should be content with this awesome opportunity the way it is and just stop asking for more... But in hypocritical fashion, here are some more ideas:)

Though more flexibility to take the final early would be a lot more convenient for many, a small window for the test - like it is now - seams very fair to prevent widespread cheating. Maybe do 2 weekdays and 2 weekend days.  

Or, though very unfair to prof. Sainani and the TAs, have 2 different versions for the test. One for the 2 week time point, and one for the end of the course.>
57:<I have sent 4 exercises  to one of the TA's Mr Rajhansa. I am not sure if he has received them as he has not responded to my direct email nor to the message on this board :(. I  cannot upload to the wiki as it does not allow attachments. So I really do not know what to do now. I can make the .srt files as and when I complete viewing a unit as  I found that blind downloading it in a batch can cause considerable errors and wrong .srt files  for the relevant videos. I am happy to help but the limitations are there. I cannot post on dropbox and other cloud servers for security issues. If someone can help including them in the wiki they can tell me and I could send  them over to them as and when I do them.(I have done units 3-6 so far and could do 1 and 2 also but the remaining 3 could be posted as I do them though actually I am in a hurry due to personal issues forcing me to finish as much as possible early at a pace I am actually not that comfortable with but with no alternative practically possible in sight so hopefully I should be able to load them early which would be an advantage to others (A silver lining of a dark cloud ;).>
58:< You can email the course TA, Raj, at <emailRedac> for now. When we get to Unit 6, I'm going to encourage a lot of discussion on these questions/examples!  So stay tuned. :)>
59:<If you have absolute risk for the first group as X, and you are told that the relative risk between the second group and the first group is r, then the absolute risk for the second group is X*r, and the absolute difference is (absolute risk for second group - absolute risk for first group) = X*r-X.

An analogy might help you understand this better: Suppose we had two cars, A & B. If I told you that Car A was travelling at 50 mph, and Car B was traveling at twice the speed as Car A, you could calculate that Car B's speed is 100 mph, and the absolute difference between the two speeds is (100-50=)50mph.

Raj>
60:<Same problem with HWK2 Questions 7 and 8.  It was impossible for me to determine the reference group from the wording of the question...must have changed my mind (and my answer) 3 times. I ultimately decided that the wording "versus" in no way declared reference, (as in "Frazier vs. Ali") and then relied on the slide presentation for guidance in picking the reference group and then did as Dr. Sainana did...pick the lowest group (my mistake).  Of course the  answer will depend on point of reference.

Perhaps rewording the questions to declare a reference group would be better...:-) or accepting two answers based on the confusion.

Love this course!>
61:<Number needed to harm - by definition, shouldn't this be in terms of events per number of persons exposed (and not per person-years of exposure)? This way, the answer works out to 1/{(20/4047)-(4/4029)} = 253.

I wonder if tagging work on this forum. I guess we could find out - @kristinsainani :)>
62:<Event per person-year is another way of saying event per person per year. So if in a particular study, we had 20 events among 100 people, who we had followed for 2 years, our incidence rate would be (20/100/2=) 0.1.

Raj>
63:<Hi. mine might be a silly question, but please bare with me and try help clarify. when calculating rate and risk ratios, is it a given that we will always divide the smaller number by the larger number across the board? cos we are looking for a value that will be smaller than 1 that we can relate to percentages? last time i did any maths was 2008! Thanks in advance :)>
64:<P(A) = P(red card) = $dfrac{26}{52}$

P(B)= P(ace) = $dfrac{4}{52}$

P(A&B)=P(red ace) = $dfrac{2}{52}$>
65:<The way I did it:

For any three-of-a-kind:

$dfrac{4}{5<zipRedac>} 	imes dfrac{3}{5<zipRedac>} 	imes dfrac{<zipRedac>}{50} = dfrac{<zipRedac>4}{<zipRedac>3<zipRedac>600}$

There are <zipRedac>3 possible three-of-a-kinds (3 aces or 3 kings or 3 queens etc):

$dfrac{<zipRedac>4}{<zipRedac>3<zipRedac>600} 	imes <zipRedac>3 = dfrac{3<zipRedac><zipRedac>}{<zipRedac>3<zipRedac>600} =dfrac{5<zipRedac>}{<zipRedac><zipRedac><zipRedac>00}$>
66:<Thanks for pointing out!  I'll see if we can get this fixed :)>
67:<Although I haven't read about it, I think we should absolutely use | in the conditional probability, to avoid confusion with the / (symbol of fraction), once a conditional probability isn't a fraction. :)>
68:<I've been scratching my head about this for sometime now. Can't get a whole number either, no matter how hard I multiply ;)>
69:<Thank you so much sallysue!
:)>
70:<Congratulations Bing2013 on making your chances of surviving an air crash better:)>
71:<Professor, This was an awesome analysis. Now probability started making sense to me :-)>
72:<I am not exactly sure of what your question is, so let me just show you how I solved the problem.  Towards the beginning of the video, the professor wrote, 

    "Let A and B be two events with P(B) not equal to 0.  The conditional probability 
    of A given B is:
    P(A/B)=P(A&B)/P(B)"

We were given P(A&B) and P(B) [P(A) was excess information], so we can solve for P(A/B).
P(A/B)=.<zipRedac>0/.75=.<zipRedac>33333...>
73:<if events A and B are independent then P(A/B)=P(A) and P(B/A)=P(B).>
74:<haha, yes this is so true - I was too caught up in the equation - thanks ;)>
75:<;)>
76:<I agree with LA. That was more intuitive to me. Unfortunately, it wasn't intuitive that 6/<zipRedac>550 was the same as 5<zipRedac>/<zipRedac><zipRedac>100. :)>
77:<hey man,, two events are independents if P(A&B)=P(A)P(B)>
78:<$z=dfrac{x-mu}{sigma}=dfrac{0.95-1}{0.1}=-0.5$>
79:<Got it! :)>
80:<I guess we have to assume that there is no dependency.  :)>
81:<I understand the confusion, because I am confused too :) 

Non-responders means the acne is drug-resistant (will not respond to drug), which will show up as a +ve result on the test. And responders have acne that is not drug-resistant, which will show up as -ve on the test (but will respond to drug). 

So, is sensitivity the fraction of non-responders who test+ve (true +ve?), or is it the fraction of responders who will be correctly predicted by the test to respond to the drug? The question is, should I take the +ve test result as the reference, or the potential to respond to the drug as the reference?>
82:<So is it true if events are independent, then P(A&B) = P(A) * P(B), but if events are dependent then one needs to use Bayes' rule, which makes P(A&B)=P(B/A)*P(A)?>
83:<ok I read more discussions and now I got it. 
thank you so much.
great course ;)>
84:<Ik kom ook uit Nederland! I'm also from the Netherlands ;)>
85:<That is correct, yes. And you know that P(B/A)=P(B) if A & B are independent. So your Bayes' rule formula reduces to the formula for independent events!

Raj>
86:<The answer graded as correct for this problem has a typo that should make it incorrect.  As given, it is obviously NOT the correct answer and a different answer looks reasonably correct.  (And, since I missed it, I would like to get the point back if possible; it ruined my perfect record :)

This is the question: "I want to compare serum vitamin D levels between three independent groups (n=10 each), but I’m not sure if vitamin D levels are normally distributed. What should I do?"

The answer given as correct is "Test depression for normality."  Depression has nothing to do with the question.

(Normally, I would not give an answer in the forum, but since this is so obviously wrong, I figure no harm done.)>
87:<Same doubt :p>
88:<3)If spine bone density is normally distributed in young women with a mean of 1.0 g/cm2 and a standard deviation of .10 g/cm2, then how many young women out of 100 would you expect to have bone densities less than .85 g/cm2?

4)If spine bone density is normally distributed in young women with a mean of 1.0 g/cm2 and a standard deviation of .10 g/cm2, then how many young women out of 100 would you expect to have bone densities greater than 1.15 g/cm2?...

i´ve had been a litle bit confused. to solve this problems que have to look for the vaule of Z. doing this. X= a varibale that describe  spine bone density of the women
 for pint 3  --P(X<0.85)=P(((X-u)/0.10)<(1-0.85)/0.10)=P(Z<1.5)=0.<zipRedac>332<zipRedac>=<zipRedac>3 women.. but the problem is that X is not the mean..there iam using that X=1, and X is a variable.. and if i use X like the mean then 
P(X<0.85)=P(((X-u)/(0.10/square root of (n)))<(1-0.85)/0.01)=P(Z<15) and that is not possible..REMEMBER THAT the mean hasnt the same distribution that the variable of X  
(iam saying that X bar  is distributed like (u, sigma over standar derivation)..
and the same for the point 4>
89:<Oh, thank you! :)>
90:<Easter egg in R ?  

:)>
91:<Let:

+/- = positive/negative test

D/~D = have disease/don't have disease

Specificity = P( - | ~D )... "Probability of the diagnostic test registering negative if you don’t have a disease." Perfectly valid. Nothing vague about it.

Sensitivity = P( + | D )... "Probability of the diagnostic test registering positive if you do have a disease". This is equal to #true positives / (#true positives + #of false negatives) and is explained in the course as such using the 2x2 table (Look at the cells you use in calculating sensitivity).

Show some respect mate. There's no problem with the material, or the notes. This is an exceptional course and it's presented well. You won't learn it in a weekend, no matter how good the equations in that manual of yours are looking so far ;)...>
92:<Are you joking? :)>
93:<Hi, I'm a pharmacist from Brazil! I'm loving this course, although I'm not so happy with the results of homework 3. :)>
94:<I don't fully understand how to plug numbers into the law of total probability formula. From the example given at 12:20 this is how I plug numbers into the formula: P(test+)=P(.991/.03)P(.03)+P(.991/.97)P(.97).

This, however, is clearly wrong, but I don't understand how it is wrong as that is what the formula indicating. The numbers in the blue box are right, but I don't understand how they can be the right numbers because they are not accounting for the "/HIV+", nor the "/HIV-".

Can anyone help me understand the difference between the example in the blue box and the actual formula given?

Thanks! :)>
95:<If the prevalence is 10% and the population finite, then the probability that all the persons in a pool of size N will be negative is not (.9)^N. For finite groups with known prevalence the probabilities of the individuals to be positive are not independent. To illustrate this, we can use the trivial case of N=population. Then since prevalence is 10%, we know that 10% of the individuals in the pool, and subsequently the pool, will be positive. (.9)^N gives us a non-zero probability that the pool containing the entire population will be negative.>
96:<As a Classic Rock fan who grew up in the 60s and 70s, I noticed many songs with lyrics that did not seem to follow approved grammar guidelines.  It did not matter whether the bands were from the U.S., U.K., Australia, etc.  Funny thing is, at the time, I don't remember caring :)  I must have been rockin'!>
97:<Hi Raj - thanks for answering my question. I just want to clarify my thinking to make sure I get this:
So, for question 4, the confidence interval would be wider if instead of sampling 100 women we sample 50 women and 50 men. The reason for that is because the 50 men would increase the height range to the sample and therefore the standard deviation would be bigger causing confidence interval to get wider.
Then in question 5, the reason the confidence interval would be narrower when we increase the number of subject in the sampling is the higher the n the more accurate our data will be and therefore CI would be narrower. 
Is that the correct way of reasoning? I think Unit 5 is harder than the previous two units. I can do calculation, but when it comes to reasoning out statistic I am easily confused. :-)>
98:<Hi Raj - thanks for answering my question. I just want to clarify my thinking to make sure I get this: So, for question 4, the confidence interval would be wider if instead of sampling 100 women we sample 50 women and 50 men. The reason for that is because the 50 men would increase the height range to the sample and therefore the standard deviation would be bigger causing confidence interval to get wider. Then in question 5, the reason the confidence interval would be narrower when we increase the number of subject in the sampling is the higher the n the more accurate our data will be and therefore CI would be narrower. Is that the correct way of reasoning? I think Unit 5 is harder than the previous two units. I can do calculation, but when it comes to reasoning out statistic I am easily confused. :-)>
99:<thanks for this nice online course.
It helps me a lot :)

I'm posting because I want to make sure, whether my previous knowledge is right.

This module's fist questions is about percent.
Normally, when I'm asked to find something in percent, I multiply 1<zipRedac><zipRedac> so that make the number in percent.
So, I tried to find <zipRedac>.<zipRedac>145(%). obviously, I couldn't find, so that i had to check <zipRedac>.<zipRedac><zipRedac><zipRedac>145

Am I wrong? or this is just a mistake?>
100:<dx is an increment. To be more clearly, lets say you want find the are of a rectangle with height f and width d then A = f * d. Going back to your question, d or dx is the horizontal distance of the rectangle between 2 consecutive and very close points. f (f(x)) is the height of the function. Many times we may not be able to find an integration theoreticlally (closed form), so we use numerical techniques to solve such an integration. A definite integration is finding the area under the curve between 2 points. We may need to split this area into infinitesimal rectangles, find the area of each rectangle, add them up, and voila this is the area under the curve. In this example by infinitesimal I mean that dx is very small i.e. the distance between 2 ponts.

I hope I didn't confuse you more ;)>
101:<The dice are all the same. As a hint, remember that this section dealt with the binomial distribution, with p=probability of a success and n=number of samples.>
102:<I do not think your reasoning is ok. You should use P(X>=112) and stick to it, simply because the question states "112 or more". A nice calculator can be found here: http://www.measuringusability.com/pcalcz.php. 
I hope this helps :-)>
103:<:)>
104:<I know it; see my post above. :) But the question was: "for calculation of a variance of probability distribution, **not for a sample variance**".
Let's look at the example from the unit's video:

x: 9, 10, 11, 12, 13;

p: 0.3, 0.3, 0.2, 0.1, 0.1

Sample variance is **2.5** 

    > var(x)
    [1] 2.5

But the variance of probability distribution is **1.64**>
105:<Prof Sainani states while deriving the Var(x) , that mu=p. can someone explain how this is so?>
106:<The distribution is symmetric. So, for example, $P(Z>1.2) =P(Z<-1.2)$

There are lots of online calculators. A popular one is http://stattrek.com/online-calculator/normal.aspx>
107:<Of course if I had bothered to read the first reply to your post (which I just did) I would have figured it out the difference in tables before writing my lame reply. Oops! :)>
108:<Thank you, mikeching! :)>
109:<With regard to the proof for $Var(overline{X})$ = $dfrac{Var(X)}{n}$, are we not taking the sum of random variables $X$ as opposed to $x-$values?  Is there a difference between the notation $X$ and $x$?  If so, then the proof should look like the following right?

$Var(overline{X})=Varleft(dfrac{sum_{i=1}^n{X_i}}{n}ight)\
=dfrac{sum_{i=1}^n{Var{(X_i)}}}{n^2}=dfrac{nVar(X)}{n^2}=dfrac{Var(X)}{n}$

P.S. This comment also applies to the proof for $E(overline{X})=E(X)$.>
110:<It took me a long time to figure out why I got questions 3 and 4 wrong.  I got even more confused when I realized I had the correct Z value, but the answers were still wrong.

I tried using the calculator given in the link, but I kept getting funny error messages and no answers, so I used the Math Is Fun chart instead.  What I didn't realize is that the chart on Math Is Fun has different values than the charts in the lectures.  I even read the intro sentence to the chart which said, "The table shows the area from 0 to Z."  Apparently this 0 is not the same "zero" as I expected.  I assumed they meant the zero that is located at the y-axis line.  Instead, this 0 is the mean.  If I was warned that this chart displayed its information differently than the chart in the lectures, then I would have gotten questions 3 and 4 correct.  I answered 43 women (as opposed to 7) because that's what the chart seemed to be telling me.  And 100-43=57 women made even less sense, since I knew the answer had to be less than 50%.  I was very confused with these two problems, but had to submit my homework anyway since time was running out.

I guess what I'm asking is if questions 3 and 4 could be not counted for the grade.  And in future iterations of this course, please, just add a jpeg of the chart (from the lectures) in the homework.  Or, if you absolutely have to link to the Math Is Fun chart, please first explain how, unlike the lectures, the chart shows the area from the mean to Z, as opposed to from Z to zero as in the lectures (and how their statement "from 0 to Z" really means "from mean to Z").

Not that I'm upset. :)  Maybe a wee bit irked, is all.  It sounds like this is the first time this course material is being offered, so I can understand that there will be little complications like this.  Overall, I adore this course.  It is the sole reason I signed up for a MOOC for the first time in my life.  I couldn't find detailed information about statistics in, specifically, medical studies in all the many places I looked.  Thank you.>
111:<Simplitia, I've replied to your other post. Essentially, when using CLT you are not coercing data, but rather changing the question. For example, suppose you have 2 populations: P1 normal and P2 exponential both with the same mean. Now your hypothesis is H0: P1 = P2. They are clearly different, however, their means are identical. So when you take samples of 50 (or larger), and use CLT, you'll find that the sample means are not significantly different. So you conclude that P1=P2 (or more accurately, you can't say P1 is different from P2). But this conclusion is clearly wrong, since we started with P1 normal and P2 exponential. Instead, your conclusion should be that the distribution of the mean from samples of 50 from P1 is not significantly different from the distribution of the mean from samples of 50 from P2, both of which are approximately normal. So by using CLT, you hypothesis became H0: mean(P1) = mean(P2).>
112:<You not only can submit them any time but you can try them as often as you wish :-)>
113:<I missed that one too, because I like everything to be precise :)>
114:<Would love to take the opportunity to thank you for this great lecture Dr. Sainani. So thank you :)>
115:<thank you; I was confused about how std err was calculated but is clear now thanks the forum ;)>
116:<ha ha, same here! :)>
117:<History is not just for historians :)

Anyway, take a look at this paper: http://www.uv.es/sestio/TechRep/tr14-03.pdf>
118:<Answering homework questions before deadlines - bad example for students :-)>
119:<> standard error (if I am not mistaken!) of (n - 1) / (n - 2)

You are. For $t$ distribution with this sample data:

SE$=dfrac{s}{sqrt{n}}$>
120:<;) Thank you!>
121:<;) Thank you!>
122:<I tried both log & Ln and they yield different answers, however, Ln produced one of the possible answers provided in this multiple choice question.  Here's a calculator link.  Press [ln] button, enter the number, press [enter] for your answer.
http://www.google.com/search?client=safari&rls=en&q=calculate+2.0*10%5E6&ie=UTF-8&oe=UTF-8#gs_rn=19&gs_ri=psy-ab&pq=calculator&cp=10&gs_id=1j&xhr=t&q=calculator&es_nrs=true&pf=p&client=safari&rls=en&sclient=psy-ab&oq=calculator&gs_l=&pbx=1&bav=on.2,or.r_qf.&fp=1b06a8483c066cdd&biw=1191&bih=687&bs=1>
123:<Thanks mikeching for the suggestion. :)>
124:<Sorry, bit of confusion between sample and distribution.

$SE=dfrac{s}{sqrt{n}}$ is the standard error of the **sample** data, which is what we want here.

$sqrt{dfrac{n-1}{n-2}}$ is the standard deviation of a $t$ distribution with $n-1$ degrees of freedom. Used when simulating data.

http://stat.ethz.ch/R-manual/R-patched/library/stats/html/TDist.html>
125:<hi 

i am a late beginner here and so have lost half the homework submissions anyway :-/. however, i am still keen on knowing how well i have progressed in my understanding of the presented concepts and so would like to know the answers of the homework assignments. i have looked around a bit but could not find a homework 'answer key' per se. i would like to cross-check my answers. coursera has this system of allowing you to submit your late tests for zero credit, but that at least lets you see what all you got right and wrong. i was wondering whether this courseware would allow for a similar automated system.

however for now, i would really appreciate an answer key for homeworks 1-5, if thats available/possible :)

thank you>
126:<I'm sure the cartoon's statment is true, considering the number of people living in homes with underwater mortgages. :-)  Which, come to think of it, is not so funny after all. :-(>
127:<You need to generate a normal distributed random variable. In R, you may use the rnorm(n, mean=whatever you choose, sd=whatever you think is suitable or makes sense)! Then use the hist function to plot the generated normal rv.

e.g.

x = rnorm(<zipRedac>0000, mean = <zipRedac>0, sd = 2)

**#Histogram with <zipRedac>00 bins**

hist(x, <zipRedac>00)

**In python, you can do the same as follows:**

**#Import libraries needed to generate normally random variable (numpy) and to plot the histogram using the matplotlib library**

import numpy as np

import matplotlib.pyplot as plt

mu, sigma = <zipRedac>0, 2

x = mu + sigma * np.random.randn(<zipRedac>0000)

fig = plt.figure()
ax = fig.add_subplot(<zipRedac><zipRedac><zipRedac>)

**# the histogram of the data**

n, bins, patches = ax.hist(x, 50, normed=<zipRedac>, facecolor='green', alpha=0.75)

plt.show()

Have fun :)>
128:<I thought I knew all about sensitivity and specificity coming in :-)

The Aha moments for me were:
1- in a case-control study, prevalence is not found in the core numbers; it will have to be factored in explicitly.
2- converting everything to a common denominator (100 in this case) lets the mind focus on whole numbers. I promised myself to use the last 2x2 matrix form to explain the results of similar analyses I would perform in the future, and use for reporting to wider audiences.

To drive home #2, imagine the Vioxx study had said something along the lines of:
"From a study comparing 4000 people taking Vioxx to 4000 people taking Naproxen for 7 months, those who take Vioxx will have only 56 GI events, instead of 121.  But, those who took Vioxx were more likely to have a heart attack (17 instead of 4); three of them actually died from these adverse reactions.  We chose to close the study and do this report in less than 7 months because the results for Vioxx seem to be getting worse with time.">
129:<This makes sense to me....I think you nailed it:)>
130:<[ PLoS Medicine Essay: Why Most Published Research Findings Are False][1]


  [1]: http://www.plosmedicine.org/article/info:doi/1<zipRedac>.1371/journal.pmed.<zipRedac><zipRedac>2<zipRedac>124>
131:<Hi,

I have made some study notes for the previous stats course I took (Berkeley EdX Course, that I warmly recommend), so I'm sharing it here in case someone else finds them useful:

- Statistical Inference:
http://www.scribd.com/doc/1<phoneRedac>1/Short-Non-Technical-Guide-to-Statistical-Inference

- Probability Distributions (with R code):
http://www.scribd.com/doc/1<phoneRedac>5/Distributions-of-Random-Variables

- Misinterpretations of Significance:A Problem Students Share with Their Teachers?

This is a fantastic paper that (gently) explains what p value is not, how misguided even statistics teachers are, what p value really is, and how it related to bayesian statistics (not written by me, of course :))

http://www.metheval.uni-jena.de/lehre/0405-ws/evaluationuebung/haller.pdf>
132:<Hi - Does anyone know how did they come up with the p of the trend in the caffeine and breast cancer question? Is it by doing a test comparing the subgroup based on the amount of beverage consumption (e.g., none vs. <1cup/d vs. 2-3cups vs. 4+ cups)? Thanks. I am very weak with statistics and therefore very easily confused. This course is fun but is alot harder than I expected. :-)>
133:<<p>I have two questions on Homework #5 indicated as incorrect, and I want to understand why. (At the moment my conjecture is that it&#8217;s because I used a leading zero.)</p>

<p>Here are my responses to numbers 11 and 12:</p>

<ul>
<li><p>I looked for the proportion of values that are more extreme than the number of excess infections, which is&nbsp; $9-6.3=2.7$ &nbsp;&nbsp;&nbsp;I totaled the counts of the columns ${-2, 1,  0, 1, 2 }$ to obtain all of the simulated results NOT more extreme than $2.7$ which I estimated to be $(30+30+38+27+40)=165$ &nbsp;leaving $835$ more extreme values. This made $frac{835}{1000}=0.835$ my estimate.</p></li><br>
<li><p>I computed the <em>z</em>-score of&nbsp; $2.7$ (the number of excess infections, $9-6.3$&nbsp;) which is $frac{2.7}{12.3}=0.2195$ &nbsp;&nbsp;Values more extreme than $2.7$ should be $1$ minus the area between $-0.2195$ and $0.2195$ on a standard Normal curve, which my calculator computes to be $1-0.1737=0.826$ &nbsp;&nbsp;Doing the same thing on a standard Normal probability table for for 1 minus the area between $-0.22$ and $0.22$ &nbsp;gives $1-0.1742=0.826$ as well.</p></li>
</ul>

<p>I&#8217;d appreciate comments. I want to understand what I&#8217;m misunderstanding or not seeing.</p>

<p>Thanks!</p>>
134:<I'm reading through this article and I'm slightly confused about the calculation of the Z score and how it corresponds to 10%.

When I calculate the Z-score I get: 163.299. If we get this is it valid to just divide it by 100 to get a Z-score that fits on the standard normal chart?

If that is the case when I check the standard normal chart the Z-score is equal to .4484, not 10%. Where does the score of 10% come from?

Thanks to whoever can answer this! :)>
135:<The phrase 'rule of thumb' very likely has its origins in the building trade, where the width of the thumb was used as an estimate, being roughly equivalent to an inch. In fact, several Indo-European languages use the same word, or a cognate, to mean 'inch' or 'thumb'.

The hoary old myth of the 'rule of thumb' law persists, despite the fact no such law existed (at least in English law), and the fact that many languages have their own version of it. This myth is thought to stem from a 1780s satirical cartoon of Sir Francis Buller, who was a prominent British judge at the time. It was given a new lease of life, I believe, by the many urban myths propagated in chain emails in the 1990s and early 2000s.

Domestic abuse is certainly offensive and abhorrent, but since the phrase 'rule of thumb' almost certainly never originated from the subject I see no problem with anyone using it given its commonly accepted meaning as 'a principle to be broadly applied'.

Just my tuppence worth :)>
136:<" that the woman who took drug X had a larger increase in bone density."  Larger increase than what?  Than Y drug?  The quiz ever mentioned what the Y drug did.  It only said whatever number the researchers found was not _statistically_ significant.  To me the quiz background said, "Drug X did show an increase in bone density (how large or small we're not saying) and we can have faith in this number we found (thanks to the p value being small enough).  Drug Y had a p value that was too large for us to be able to put faith into the number we found, and we're not even going to tell you if we found an increase or decrease since our number is irrelevant anyway.

Hmm, now that I re-read your question, perhaps you're saying "larger increase in bone density than they had before they took the drug."  In that case, forget what I said in my first paragraph :) , you already understand what I said in my first paragraph.  However, I'm confused then why you ask if p-values should be believed or not.  I mean if they did their math correctly, and correctly applied Bonferroni or whatever (if needed), then you can trust and believe their p-value.  Granted, that does seem to be a big "if".  But let's assume the study was published in a peer-reviewed journal and a peer reviewed their math; then, yeah, sure, believe their p-value.  Though this is not the same as believing that the drug worked or not or did damage.  That's a whole other value than the p-value.  So in terms of trusting that a drug worked or not, yeah, it would be reassuring to have more tests done by other people that had the same results as the first test (and also did the tests detailed enough to get tiny p values that increase the faith we could put into what they found).

Did any of us answer your question?  Also, note, I'm just a lay person and no expert.  I'm just presenting what I believe to know derived from listening to these lectures. ;)>
137:<I think the point that is reinforced throughout the course is to think critically about interpreting "significance". While a result that is clinically but not statistically significant could have happened by chance as you say, from what I have gleaned from this course is  that this is probably going to be the case for most small n samples. But if a clinically significant result emerges, further trials could then be warranted and if the results are replicated over and over again then the statistical significance doesn't really matter. Or maybe there's some kind of clever regression you could run across all the trials (combine all the data) to assess statistical significance? Oh, and if you know of any peer-reviewed journals that would accept research with n=1 sample sizes, let me know ;)>
138:<I guessed, got them both wrong.  What were the odds of that?  :)>
139:<That was my guess, but I cannot confirm that most of the data was collected after 9/11. Anyway, we will never know. :)>
140:<I been thinking about this problem myself with no help so far. But I think I finally came up with an idea.  First lest start with the coin toss stim since its much easier to understand.  To program this all you have to do is randomely draw either 1 or 0 with equal probability P(1)=P(2)=.5 - this is pretty easy right? All you need is the probability and numbers to draw from. Ok now for now for idea how to simulate when we are just given the mean and SD.  I think this is possible because essentially the SD tells us the probability in which to draw the result.  Example, supose the mean is 30 and the SD is 5, that means that -25 to 35 about 68% (remember the 68–95–99.7 ) 3 sigma rule. We can actually look up the z-table and get very percise down to the probability of drawing say 55.  Z= 55-30/5 - about 1 in <phoneRedac> With that you can just set the your computer to randomely draw 55 with this probability. You do this for the entire range say 0-60 and just plot the data out.  I think this should work! Sorry if I confuse anyone.>
141:<nevermind - it could do unequal sample ;)>
142:<Yeah it's a bit unfair that getting 2/3 right is marked the same as getting 0/3 right :-(
But life is unfair! :-)  (And I had *all three*, but was careless when transferring my answers over - too tired).

As far as clinical effect goes, I think I would consider anything over 2.0 or under 0.5 as becoming significant - twice the odds of surviving a disease, for example, would really make a difference to my life!>
143:<Folks, the error in the formula for SD [missing square sign after (Xi-X)] in the unit 1 summary pdf is still there. Can you please change it so those who are new to stats won't lose their heads if revising from it?

It was pointed out earlier, but we know we have kept you very busy :-)
https://class.stanford.edu/courses/Medicine/HRP<zipRedac>58/Statistics_in_Medicine/discussion/forum/i4x-SampleUniversity-HRP<zipRedac>58-course-Introduction_to_Medical_Statistics/threads/51c<zipRedac>a37b<zipRedac><zipRedac>4<zipRedac>9c<zipRedac>a<zipRedac><zipRedac><zipRedac><zipRedac><zipRedac><zipRedac>be>
144:<No, because in roulette there are also only 18 even numbers. Zero and double zero don't count as being odd or even, so even if you were to bet the same amount on odd and even, your expected value is still less than one; (28/30 - 2/30).

The house always wins ;)>
145:<thank you so much guys ;)>
146:<And the former president's name is "Reagan", not "Regan" :)>
147:<It won't accept my answers! Technical problem over there! ;)>
148:<I think this was some kind of score from a questionnaire, like the number of dates or something ;)>
149:<Thanks for the feedback! The homeworks are harder than the quizzes by design!  I do want to challenge you. I will make you calculate a few things by hand, especially when I think it's instructive to go through it. Some of the worst errors I see in medical papers could have been caught by simple hand calculations; so even though you will mostly be doing things on the computer, I do think it's worth going through some of the easier math by hand! 
I hope we will have a way to avoid penalizing for carry-through errors in the next version of the course, or I may revise the set up of this particular question. But the good news is, there are none of these types of questions on the final exam :)>
150:<Is there any kind of guidance what variable should include in model or we can only go and search by trail and error method. Profesor Sainani at Obama ratings looked at beta coefficients of variables and elected influenced ones, and that was criteria for putting some variable in regression equation. 
I am wondering does next kind of thinking could be guiding for selecting variables for multiple linear regression? If, for example we have 10 diferent variables, and we want to choose few most influenced and make linear regression model, could we at beginning look at the correlation between variables and observed outcome, and correlation between variables its self. Those variables that are higly correlated with outcome and have low correlation with others variables, will certainly be in the model. Others that are correlated with outcome, but also correlated with other variables (colinear), will be chosen by the beta coefficients. Just like et the end of video politics and Obama. Help, is this kind of thinking have any sence?
Thanks :)>
151:<e is base of the natural logarithm (ln). It is constant value (something like ? (pi)), and it amounts 2,71. So when you are calculating e raised on some number, for example Profesor Sainani calculated e raised on 2,12, it is calculated like 2,71 raised by 2,12 and that equals 8,27. Hope I helped :)>
152:<I suspect someone is going on (well deserved) holiday from about mid-August onwards ....  :-)>
153:<Don't we all deserve one? :)>
154:<It is a bit like a politician who says "He has not cheated on matter X". It does not automatically prove he/she is of absolutely honest character. They haven't told you about/been tested on matter a,b,c,d yet .... :-)>
155:<Hi Dr. Sainani - I think you have said earlier in the course that you will look into offering CME credits for the medical professional students in the course. I wonder if I can get CME credits along with the Statement of Accomplishment for the course. If so, how do I get the CME credits? Thanks again for a great course. I learned alot and will be referring back to the course materials for the rest of my medical career. :-)>
156:<I have loved this course. Despite going into this with a major part of my job being interpretation of the medical literature, I have learned a TON.    

By way of constructive criticism, I'd like to suggest one minor improvement.  As a healthcare professional, I have had the safe use of decimals drilled into my head.  In future courses, I strongly suggest modifying how decimals are presented.  When writing one tenth, the safest way to avoid missing the decimal is to add a leading zero - so "0.1" as opposed to ".1".  

Again, thank you for the excellent teaching.  Some version should be a required part of CE for practicing pharmacists and physicians :)>
157:<Thank you for bringing this up; I was going to write my own post on the subject.  While I regard Ronald Reagan as an appallingly bad president, he does at least deserve to have his name spelled correctly.  And so does his confounder.

Ironically, this error happened (for the second or third time) on slide 144, the slide with "(no graphing, no thinking)."  This is also the slide with the headline "Viola!" rather than "Voila!"

Some of us do actually like to think now and then, and would thus appreciate it if when a new methodology is mentioned (in this case, stepwise selection), we might be given some clue of how it works.  Or at least soothe us by playing a tune on your viola. :-)  (Sorry, couldn't resist.  Didn't take any Vitamin D today.)>
158:<@ Hut: Well hopefully we'll be walked through a clear account of how to order linear models in terms of impact of adjustment. :)>
159:<You're right!  This is a case of naming a variable something short for ease of programming and then forgetting the actual spelling ;) We'll fix it on the next round.>
160:<Great for you friends to hear that you completed the course :) I just finished it and I was wondering if I will get a statement of accomplishment if I have exactly 60 % or maybe 60.3% I am really grateful for this course and I will be very happy if I get a statement of accomplishment :)>
161:<You want:

$p=dfrac{e^{eta x}}{1+e^{eta x}}$

$p=dfrac{0.36}{1+0.36}$>
162:<Great course! I really love examples from real scientific papers. Possibly the 'take home message' is: 'do statistics for your papers if you are an expert, otherwise find an expert' :)>
163:<joycelee, oddly enough :), I think that both of these statements are correct. I agree with your statement. If you increase homework by 1 hour, you are correct that the $ln(odds of book smart)$ goes down by 0.039. 

However, the statement Dr. Sainani made is also correct. If you increase homework by 1 hour, the odds ratio is $e^{-0.039}$. This is 0.96, or also down by 0.04 compared to an OR of 1. 

This is a _coincidence_.

If beta was something different, say -0.5, the  $ln(odds of book smart)$  would decrease by 0.5 for every 1 hour increase in homework. The odds ratio for increasing homework by 1 hour would, however, be $e^{-0.5}$ or 0.61. This is a 39% decrease in the odds, not a 50% decrease.>
164:<I would also like to thank Dr. K and everyone else involved in putting this course together. 

The videos, notes and quizzes were of a really high quality and the whole course was really engaging and interesting - in contrast to the formal statistics I did back at Uni. 

The highlight for me was the many ways that statistics can go wrong - thanks to this course I know that if I eat red-meat, there's no need to drive extra carefully :)>
165:<Just want to say thank you to Hut, Raj & Tracy for your comments.  They enabled me to work through the problem correctly =)>
166:<This was my first online course and I absolutely loved it. I just finished it (98% :-) ) and am almost a bit sad that it is over.

As a scientist I had a good working knowledge of statistics. However I did not understand a lot of the underlying fundamentals, as I somehow managed to go through my education without ever taking a statistics class.

Over the years I bought at least three statistics books with the intend of reading them, but I never even made it through the first 10%, the topic was just too dry.

So I would like to thank you, Prof. Sainani, for this excellent course that finally let me understand statistics from the bottom up. You managed to present it in a way that was enjoyable while still feeling very relevant. And the excellent structure of short lecture bits with small quizes in between will most likely make the knowledge I gained here stay with me for a long time.

Thank you!>
167:<Thank you guys for your help. What I am exciting about in statistics is the fact that you cannot be absolutely sure about anything – however, this is also the reason why it can be so irritating sometimes :-) The fact about hypothesis testing is that neither hypothesis is “true”. After a test, you end up with a p-value that must be explained. The idea is to keep “significance level” low and “power” high, and yes, in the most cases, we try to formulate our hypothesis in such way that we “go” after “the alternative one”. However most importantly is to formulate the null hypothesis based on a clear probability model – something you can calculate with – otherwise it makes no sense at all. Anyway, I am still puzzled about the way we can explain p-values. Yes, if a p-value is 0.5, this means we cannot reject null hypothesis. But do we have any other indication? Or may we use the results from the test in order to formulate our next step? Is that a kind of “bias”? I think I need to research the subject more deeply;-). Thank you.>
168:<Here is the link for a calculator with the "e" function.  
http://www.google.com/#bav=on.2,or.r_qf.&fp=<zipRedac>871<zipRedac>a4a2cebd080&q=calculator
To use it: 
press e (it is located in lower left corner of calculator),
then ^ (it is located on the number <zipRedac> key- so hold down the shift key and press <zipRedac>), 
then enter the number you want to exponentiate, press equal sign (=) for your answer. If you entered 2.12 (the example at the end of U9/M1/Pt1), then the answer should be 8.331>
169:<Also from me a huge big Thank you. I especially enjoyed that you explained most of the content with regard to real studies. I am so glad that I joined this course and it will certainly help me with the upcoming Statistics exam at my university next month :)>
170:<Hi Raj (or fellow students),
Would you be able to add to the following explanation to give a bit more detail?  For example, when I drew my line in the first plot to arrive at the intercept, it did not go through an x=o.  Also, in determining slope (rise/run) or (y/x), it is unclear where the numbers for the calculations came from. Is there an intermediate step that is missing?

"You have to imagine fitting a straight line to the points in the plots. The plot with 12 bins (which goes through X=0) reveals the the intercept. From the first graph, we can estimate that the slope is roughly: -2.5/12=.208; the slope from the second graph is: -1.7/9=.188"
Thank you =)>
171:<Thanks a lot to Dr. Sainani and all those involved with this course. I am a medical graduate and this course really helped me how to read and interprete medical literature. This will help me a lot in my career and hopefully, I will be able to publish papers by performing various studies!:)
The content was very good and superbly presented. Loved the short videos, summarries, ppts and quizzes. The format of the course was very engaging, flexible and relevant from a medical point of view.   
Please continue making such online courses. Would love to do them in future too.>
172:<11. Which of the following factors is associated with the greatest decrease in **DSST score**?
:D>
173:<If you like to download video lectures in a better quality(720p) then those posted in a wiki(240p) you may use links below. That movies are posted on the same server as  videos from the wiki, so I have no idea why course stuff don't provide us links for them. Such low resolution as 240p makes many slides unreadable so they should be called audio lectures :-D

----------
<h2 id="unit-1">Unit 1</h2>
<p><a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+1+Module+0.mp4">Unit 1, Overview/Weekly Teaser</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+1+Module+1.mp4">Unit 1, Module 1</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+1+Module+2.mp4">Unit 1, Module 2</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+1+Module+3.mp4">Unit 1, Module 3</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+1+Module+4.mp4">Unit 1, Module 4</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+1+Module+5.mp4">Unit 1, Module 5</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+1+Module+6.mp4">Unit 1, Module 6</a>  </p>


----------


<h2 id="unit-2">Unit 2</h2>
<p><a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+2+Module+0.mp4">Unit 2, Overview/Weekly Teaser</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+2+Module+1.mp4">Unit 2, Module 1</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+2+Module+2.mp4">Unit 2, Module 2</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+2+Module+3.mp4">Unit 2, Module 3</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+2+Module+4.mp4">Unit 2, Module 4</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+2+Module+5.mp4">Unit 2, Module 5</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+2+Module+6.mp4">Unit 2, Module 6</a>  </p>


----------


<h2 id="unit-3">Unit 3</h2>
<p><a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+3+Module+0.mp4">Unit 3, Overview/Weekly Teaser</a><br />
<a href="https://s3-us-west-1.amazonaws.com/prod-edx/MedStats/Video720p/Unit+3+Module+1.mp4">Unit 3, Module 1</a><br />
<a href="https://s3-us-west-1.amazonaws.co>
174:<Congratulations on the perfect score!  And I'm glad to see that you're thinking in distributions now :)  I will post a histogram of scores after the course closes (give us a few days to put it together!).>
175:<Congratulations on finishing the course. I'm so glad it helped you to "get" statistics! :)>
176:<Thanks so much for the nice note!  I won't try to respond in Russian ;)>
177:<Thanks for the praise, Sheridan!  I'm glad to hear that I was able to hit the right balance of enjoyable and rigorous. I hope I can get many doctors to enjoy reading data tables ;)>
178:<Glad you enjoyed the course and that it was a good "painful"! :)>
179:<Congratulations on passing!  This is the same content I teach at Stanford, so if it wasn't hard I'd be worried ;)>
180:<1. First using the beta and the given number of years, calculate p
 2. Convert p into an odds ratio using the formula OR=p/(1-p)

Raj>
181:<This is the best Stats course I have taken so far. I have taken Stats for Math major in college and Udacity's Stats 101. My college Stats class focused too much on Mathematical proof and neglected application. Udacity's Stats 101 is too basic. Stats in Medicine has the nice balance. I love the optional modules and readings. Thank you professor for sharing your great articles. Otherwise, I have to pay for them :)

I just finished my final and made a few mistakes. I am waiting for the solutions so that I can review the topics I am still weak in. It has been a great learning experience and I learned A LOT. I am not in medical field but the Statistics concepts that I learned in this class applicable to the field that I am interested in i.e. Data Science.  

Thank you for putting together this excellent course and make it available on-line for free! The course quality is top notch!

<nameRedac_anon_screen_name_redacted> <nameRedac_anon_screen_name_redacted>>
182:<I just wanted to thank everyone who created and ran this course! I had a wonderful time, and the course was super-informative. This information will be put to good use in the future :)>
183:<Great advice for people that are feeling anxious about the deadline (ie, the final). Thanks for sharing....:)>
184:<This was an excellent course all around.  For me, if it had a slogan, it would be, "the red or blue pill" - it really changed how I view medical research, now I look at it with trepidation - I'm not sure if I can fully trust a research again.  - I'm worry about medical research - probably part of the reason why we a are still taking Tylenol for a common cold ;) 

Anyways, for me my favorite modules were, 
1. Baye's Rules because I was never able to understand it - still don't fully grasp it but it helped a lot. 
2. Not a module but I have never heard anyone explain confidence inerval the way she did and it was spot on. 
3. Interestingly not medical related but I thought her explanation of Nate's Silver idea of the CDOs were very insightful and now I have an idea how what went wrong, those idiots confused themselves over correlations, haha, now I can sound like a financial genius. 
4.  The examples were great as well.  
5.  if I had to choose one though, it would be the oversampling module.  I enjoyed it like watching a movie unfold. 

Oh and here is an idea for kickstarter project: hire a bunch of statisticians and critically analyzed the stats of big head line papers or random selection and call the authors out on it.  You can make money by either selling the info to news outlets or through a subscription based and you would be doing a world of good. 

That's my 2 cents -  Thanks again for the  class. 
AL>
185:<Agreed.  This is an excellent course and you are able to explain complex statistics in a fun and engaging way.  (And the price was right, too)  :)  Thank you for the enormous effort in curating the content for the course and all that goes into keeping it running.>
186:<You mean scientists really play minecraft all the time ? ;D>
187:<It is indeed difficult to tell you without directly revealing the answer/direct method.
It would help if you were to write down what are your groups that you are studying - single , two or multiple, correlated or not, normal or not etc etc
.What you really need to do is consider how outcomes which are non-concordant differ from say that of a flip of a coin.That is the probability that you need to calculate and compare .If it helps there is a very similar example worked out in the lectures.(practically similar  but you don't want to "burn up" your face with worry as the actual process is simpler than it seems:)>
188:<Thanks! I'm glad a few of my modules had an unfolding plot to them!  If you start the kickstarter project, I'm happy to contribute :)>
189:<I have to add to all the praise and say that you have opened my eyes to a whole new perspective in stats.  This should be a mandatory course but it should be only mandatory if YOU TEACH IT :)

Thank you again for you!>
190:<I'd also like to add a huge vote of  thanks to Kristin and the team.

I took this course on the basis that I'd gone through Kristin's "Writing in the Sciences" Coursera course (albeit after it had technically ended), and was very impressed with her obvious thorough knowledge of statistics and her presentation style.  This course has not disappointed!

I'm neither a Statistician or Medical professional, but wanted to understand Medical Statistics better, and believe that this course has exceeded my expectations.  I've found the Homework questions particularly challenging, but nothing worthwhile is easy, is it?  I loved the exam style  -  having 26 "mini" exams was far, far, better for people with busy lives than one long exam.  I did think I may not be able to pass the course at all if it were more like a conventional exam, as finding even an hour of uninterupted time is very difficult.  Thank you for making it the most user-friendly exam I've ever taken.

I'd highly recommend this course to anybody!

Thank you so much, Kristin.       :-)>
191:<Just a small point. The mean is -0.053 dollars not 0.05 cents as Prof S says in the video.  So on average, you will lose $1.04 and win only 94 cents.  A slightly more serious situation! :-)>
192:<Thank you so much Dr Sainani and the TAs for such a great course! It provided a very good overview about the core aspects of statistics in a condensed and interesting manner - I felt the overviews about odds ratios, RR and the like, as well as the different types of studies used was excellent and really cleared up something that has been confusing me for quite a while! Given the time restrictions, I think the modules on the statistical tests are terrific - perhaps there could be additional detail added in a "Statistics in Medicine 2" course? :) 

Once again, thanks very much for putting such a great course out there! 
<nameRedac_anon_screen_name_redacted>>
193:<Thanks for your answer.
I have already checked them and I cannot see the point in what you said... Hopefully I will see the final answer after the deadline (16th August).
Regards :)>
194:<Thanks for your answer.
I've used the table and I've done the exercise again (for the fifth time) and I still get the same results...
Hopefully, we'll get the correct answer by 16th August ;)
Regards>
195:<yes I was munching on chips and having a good time with some of them; others I had to open two screens while simultaneously taking notes.  

* It would be incredible if you contribute - I think a grading system like A-F of stats in papers would be useful. I only have a elementary understanding of stats though - so I'm not sure if I can start this - I can certainly do the tech end though.  Perhaps you can be the fearless leader?  Could be a good way to have your students participate as well ;)>
196:<Don't you think it is strange question or I have missed something

> You are performing a cohort study to look at risk factors for breast
> cancer in **postmenopausal women**. If the probability of **developing
> breast cancer among smokers** is .05 for the study duration, then if
> you **sample 100 smokers**, how many do you expect to develop the
> disease? Give the expected value +/- 1 standard deviation

I can not understand how smokers and postmenopausal women are connected? I agree that it is possible smoker=postmenopausal women but in this task. Maybe someone fixed this one?>
197:<I agree, "trend" is misleading, but unfortunately it's industry jargon meaning simply that the result was logical/predictable/explainable but not statistically significant.  In the conversational use, "trend" implies 3 or more, but in science it means 2 or more.  For better or worse (I vote worse ;)>
198:<Thank you! I am taking classes online to restart my brain after a 25 year break. I am trying to keep up with my 15 year old who is starting PreCalc in September. What an incredible resource these online class are for everyone! :)>
199:<Sounds great! I will try it :)>
200:<It's dangerous to conclude causality from an observational study like this! This is a hard topic to study as a randomized trial though ;)>
201:<Congratulations on a great score and hope your baby picked up some stats along the way :)>
202:<I am new to online courses, this one being my first and my first course on stats since high school. I sure am glad I started here because it encouraged me to do more!! An amazingly well-structured course, I simply loved the many different examples from real publications and Dr Sainani's Stanford class - thank you!!! The concepts were talking points with my friends and my wife :-)!! Though work was busy at the same time, this was worth the late night hours. I'm not sure whether I get a distinction or not since my cumulative score was 90% and not above. Anyway a big THANK YOU to the whole team!!!

PS. When does another scientific writing course start?>
203:<Upfront, I am new to online courses with this one being my first and my first course on stats since high school. I sure am glad I started here because it encouraged me to do more!! An amazingly well-structured course, I simply loved the many different examples from real publications and Dr Sainani's Stanford class - thank you!!! The concepts were talking points with my friends and my wife :-)!! Though job was busy at about the same period, this was worth the late night hours. I'm not sure whether I get a distinction or not since my cumulative score was 90% and not above. Anyway a big THANK YOU to the whole team!!!
PS. When does another scientific writing course start?>
204:<:-)>
205:<Thanks so much, Andy, excellent detective work! R is such a great program, I too would just like to get a handle on it. We work mostly in SPSS, which is fine, but so different. SPSS is like Windows and R is like unix raw, I'd rather have my hands on the data ;)>
206:<Thank you Dr. Sainani for this opportunity and for the enthusiasm on every lecture. Your students are very lucky to have you as their professor. Thank you to the TAs who helped with the questions. Thank you to the students who posted questions and to all of them who try to help with the answers. Thank you to Stanford University for making this wonderful class  available for free for anybody interested in learning something very useful.
THANK YOU!I consider myself lucky for this great opportunity
<nameRedac_anon_screen_name_redacted> from New York :)>
207:<Puebla, ¡México! Muchas gracias Dra. Sainani, no tiene idea cuánto me ha ayudado este curso y para lo que me servirá en los próximos años. Mantener entretenidos e interesados a los alumnos con este tipo de clases es difícil y ud. lo hace de una manera ¡¡impresionante!! Sin duda alguna esto ha aumentado más mi interés por estudiar bioestadística. :D

I really appreciate all your efforts to have made possible this MOOC. Never heard of #FOAMed?  You should join the conversation in the twitter-averse! Really, you should!!>
208:<Hi, I just finished my exam and I got 39.6% from possible 45%! But I started the course quit late, from 5th week. So I don't have enough score from homeworks and I have an average of 58% in total!Just 2% less :D
Is there any way that I can get certificate?!! I really need it for my job :(>
209:<I didn't do as many homework assignments as I could have. If I had, I would have completed the course with a certificate. The final exam, I passed - Yay :-) that made my day!! Thank you Dr Sainani and colleagues for a great class and even though I was sick for a few weeks with Lupus issues; I could go back to the lessons and complete the final with a passing grade :-)>
210:<shukriya .. bahut achcha kaam..:)  means **thank you.. a good initiative...

hindi..**>
211:<Cairo, Egypt
shokran :)
(arabic)>
212:<This was a very challenging course for me. I've had so many tests, formulae and interpretations going through my head, at times it was really hard to focus on just the info I needed to solve a particular bit of homework and the final. It was a fast-paced course too, I found, with a lot of information. But I made it to the end and passed. Wished I had gotten 90 but I ended up with 81%, not bad for a guy who has never been to university, I guess :) I'm very appreciative of the the amount of work Dr. Sainani put into the lectures. At no time did I ever find the material boring and concerning the subject matter, that's probably pretty amazing. Thanks!

I only wish there were more practice questions. I'd like to continue to improve my skills on stats. If anybody has any suggestions of where to find good practice problems that are related to the course in a text (hardcopy or online), I'd love to hear about it.>
213:<Congratulations on the distinction! I'm glad the course has helped you see how fun statistics can be! :)>
214:<Great to see a high school student in the course!  Great score, and hope you rock the AP exam! Let us know how it goes. And hope to see you at Stanford :)>
215:<Dear Prof. Sainani!

Although I learned a bit of Statistics at the University, I didn't realize until now that there are "Statistics" and "Statistics":-) Everything is so much brighter now!
It was quite challenging to listen to the modules day by day, night by night, having four little children around me (ages 7, 5, 3, 1). I'm not sure whether I would perservere if the teacher was somebody else.
You are an excellent example of what teacher should be and what approach should use. I believe it is a gift. And You are certainly gifted. You have dissected statistics in such a way that everyone understands. This is a gift as well.
The Stanford students are privileged to have such an engaging and motivating teacher. Thank You for letting us be a part of something really huge!
Thank to all of Your assistants as well. I do believe they helped a lot, a lot...

Greetings from Zagreb, Croatia>
216:<Podzi?kowania z Polski  - najlepszy kurs online w jakim bra?em udzia?.
Thanks from Poland - the best online course in which I have participated :-)>
217:<You are even greater now in my eyes! greetings to Your children as well:-)>
218:<The Binomial (McNemar's test) is for one tail(double the value for two tails) Bin N=10, p=).5. x<=1 which is 0.0107 .For two tails it is  0.0214 ie 2.1%>
219:<Here another Peruvian reporting my gratitude for the amazing learning experience. 

It was a great opportunity and hope to see my disctintion certificate available soon :)

Thanks Dr Sainani>
220:<Wroc?aw, Poland. Dzi?kuj? bardzo :)>
221:<thanks a lot, Dr. Sainani! I know these answers won't increase my final result significantly, but I wondered if I answered right :)>
222:<I want to first send a huge Thank You to Dr. Sainani and her staff for an amazing course! You were very engaging and it was obvious that you are your team put your heart and soul into this. I took an undergraduate and graduate statistics course, but because this was presented in the framework of medical statistics, I learned a lot of new concepts. It has made a big difference for me, and I am so proud to put on my resume that I completed a statistics course from Stanford University.

It is heartbreaking for me, because I missed the 90% distinction by ONE QUESTION on the final! I am a bit OCD, so it is so hard for me to get over this. I keep thinking about the questions that I could have answered differently -- I know what the answers are. Also, I did not rely on others' help on the discussion forum to take my homework, which would have inflated my homework score. I found the discussion forum hard to navigate, and with as many hours as I was putting into the course, I did not have any time left to research the answers on the forum. Also, I wanted this course to be a true test of my own knowledge, not what I could learn from others' input, so I feel like my score was accurate to my own abilities. If I had spent time on the forum, I am sure I would have my distinction right now very handily.

Through reading others' posts about being so close, I was wondering if there would be any accommodations or a final "curve" of 1% for those who were SO CLOSE such as myself! If not, I will have to live with this, but I just put in so many countless hours and would have been so happy to have made the distinction cutoff.

Regardless, thank you so much for your passion for statistics and your commitment to this course. I am already signed up for Writing in the Sciences and look forward so much to taking another course with you!! :-)

If you have any thoughts on making any accommodations for those of us who were PAINFULLY close, it would make a difference.

Thanks again,
<nameRedac_anon_screen_name_redacted>>
223:<tell me what are the question ?
i will help you :)>
224:<I think I have to disagree with your disagreement. :-)  (Hmm, that seems like a double negative; maybe we really agree?)  It's certainly true that an introductory statistics class can be taught without a large amount of math; e.g., no calculus.  But at some point, if you want to really understand the concepts, you have to sit down and do some math.  And most people don't fully grasp the mathematics until they actually do some 'mechanical' calculations.  I also don't agree that learning to use the software is completely different from understanding statistics.  If you don't have some understanding of the concepts, you won't use the software correctly, and your results will be highly accurate but meaningless.  I'm glad that Dr. Sainani gave us guidance on how to choose the right statistical method, but given that we never actually DID some of these methods, how are you going to successfully perform them with ANY piece of software and have any confidence in the results?>
225:<Wholeheartedly agree :) And so would my patients if they knew!>
226:<I think that apart from a very few where the wording was just simply ambiguous in terms of the english sentence construction used, most of the quizzes did test you on whether you had understood the underlying broad concepts on which test to use or should have been used and were sometimes quite subtle. Some were quite straightforward to complete where the concept was simple, and helped to boost your confidence ..perhaps deliberately... :).  My view.>
227:<Thanks for the post! I think the last example of material at the link brings a very good point. As applied to human drug studies, the parallel is that all the humans are very different, and there could be no (or vanishingly small) direct correlation between the fact that you take drug and medical effect. But as you start averaging, and use very large groups of people, you can start seeing trends (even tiny). I guess the conclusion is that the drug is not doing any good for you personally, but is of some merit for public health (financially optimizing national health care budget). Please notice that the bird example has a large number of observation data points analyzed (<zipRedac>0000), so statistical power of such study is big, that's why the trend is visible. 


To see the effect projected to an individual, smaller studies could be used, say 30 birds observed. In that case the observations could be more related to each individual (or could be simply findings by chance :-)). Less random noise (more correlation) -> you don't need a lot of data in a sample to see the effect! I am not saying <zipRedac>0000 points is worse than 30, it just starts bringing up small details often irrelevant in practice. If you have a systematic component and noise on top of it, you need dampen the noise by multiple averaging, while keeping the systematic portion (in a simplistic homogenous group not affected by averaging). Then if you want to see systematic effect Es, you need to design study with enough of data points to bring Erandom averages below Es to see the effect.

At any rate, seeing x-y scatter plot for all the data available is extremely instrumental.>
228:<Ditto; I worked hard and got a 99% (just shy of the elite 67 who got 100); but no distinction for me either. I wanted to show it to my mom to prove I had made something of myself :)>
229:<Dear Staff,
I tried to verify the certificate, however when I followed the instructions on the website for certificate verification process, the official Stanford OpenEdX Team public key in unavailable.

Thank you very much!
:)>
230:<Why "elite"? Are you sure such a small fluctuation can't be due to... chance? :)>
231:<Not that I was going or needing to show it anyone anyway, but it does seems that the course organizers go to extraordinary lengths to diminish the value of the certificate. The only thing left is to put "void void void ... not a real certificate ... " in watermarks :D 
Compare with https://www.edx.org/sites/default/files/edX-SampleCertificate-x900May28.png, for example.

The course was great though. Thanks a bunch to all involved!>
232:<Well, it's quite clear what certificate ISN'T :"NOT EQUIVALENT TO ON-CAMPUS COURSES..DOES NOT AFFIRM THAT THIS STUDENT 
WAS ENROLLED ...AT STANFORD UNIVERSITY ...DOES NOT CONFER A STANFORD UNIVERSITY GRADE, COURSE CREDIT OR DEGREE... DOES NOT VERIFY THE IDENTITY OF THE STUDENT."
My question is what IS it then? And why would you put FREE on it? Did any of "dishonest types" try to c<nameRedac_anon_screen_name_redacted>im a refund :)?
Are you p<nameRedac_anon_screen_name_redacted>nning to do the same "free online offering certificate" with a CME credit? Tnx.>
233:<I am (post-course!) unable to load Deducer or R, despite having re-installed  several times using the complete install package on www.deducer.org website.  I am using Windows 8 64 bit. I have both JGR and R icons on my desktop, but nothing happens when I click on them.  No error message, nothing.  Have also tried  going to this location: C:Program Files (x86)RR-2.15.0in and using right click --> run as administrator on the deducer and r exe files there.  It brings up the "do you want to allow the following programme to make changes to your your computer" box, I click yes, nothing happens.

Has anyone else had this problem and found a solution?  I have now spent several hours trying various fixes without success.  

Thanks! <nameRedac_anon_screen_name_redacted> H>
